[2024-11-20T09:44:59.610+0700] {processor.py:186} INFO - Started process (PID=79516) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:44:59.612+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:44:59.616+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.615+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:44:59.739+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:44:59.812+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.810+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:44:59.892+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.891+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:44:59.898+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.898+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:44:59.903+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.902+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:44:59.906+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:44:59.906+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:44:59.985+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.397 seconds
[2024-11-20T09:45:30.649+0700] {processor.py:186} INFO - Started process (PID=79759) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:45:30.652+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:45:30.657+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:30.656+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:45:30.873+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:45:30.957+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:30.956+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:45:31.015+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:31.015+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:45:31.023+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:31.022+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:45:31.025+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:31.025+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:45:31.027+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:45:31.027+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:45:31.101+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.483 seconds
[2024-11-20T09:46:01.509+0700] {processor.py:186} INFO - Started process (PID=80064) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:01.514+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:46:01.526+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:01.525+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:01.818+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:01.956+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:01.955+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:46:02.093+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:02.092+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:46:02.102+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:02.102+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:46:02.110+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:02.108+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:46:02.117+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:02.116+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:46:02.249+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.821 seconds
[2024-11-20T09:46:32.551+0700] {processor.py:186} INFO - Started process (PID=80372) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:32.557+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:46:32.564+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.562+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:32.759+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:46:32.806+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.806+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:46:32.867+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.867+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:46:32.877+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.876+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:46:32.880+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.879+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:46:32.882+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:46:32.882+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:46:32.935+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.419 seconds
[2024-11-20T09:47:03.299+0700] {processor.py:186} INFO - Started process (PID=80671) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:03.300+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:47:03.303+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.302+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:03.386+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:03.428+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.427+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:47:03.474+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.474+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:47:03.480+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.479+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:47:03.482+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.482+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:47:03.485+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:03.485+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:47:03.527+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.245 seconds
[2024-11-20T09:47:34.925+0700] {processor.py:186} INFO - Started process (PID=80973) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:34.928+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:47:34.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:34.929+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:35.033+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:47:35.106+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:35.105+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:47:35.165+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:35.165+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:47:35.175+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:35.174+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:47:35.179+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:35.178+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:47:35.182+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:47:35.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:47:35.228+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.319 seconds
[2024-11-20T09:48:05.717+0700] {processor.py:186} INFO - Started process (PID=81325) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:05.721+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:48:05.727+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.725+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:05.818+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:05.873+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.872+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:48:05.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.928+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:48:05.936+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.935+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:48:05.939+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.939+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:48:05.943+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:05.942+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:48:06.001+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.320 seconds
[2024-11-20T09:48:37.500+0700] {processor.py:186} INFO - Started process (PID=81629) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:37.502+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:48:37.505+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.504+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:37.650+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:48:37.726+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.726+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:48:37.786+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.785+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:48:37.790+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.790+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:48:37.792+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.792+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:48:37.794+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:48:37.794+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:48:37.841+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.359 seconds
[2024-11-20T09:49:08.422+0700] {processor.py:186} INFO - Started process (PID=81948) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:08.427+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:49:08.430+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.429+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:08.546+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:08.612+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.611+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:49:08.691+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.690+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:49:08.728+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.728+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:49:08.755+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.747+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:49:08.779+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:08.778+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:49:08.847+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.440 seconds
[2024-11-20T09:49:39.553+0700] {processor.py:186} INFO - Started process (PID=82242) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:39.564+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:49:39.570+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:39.568+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:39.810+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:49:39.933+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:39.933+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:49:40.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:40.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:49:40.170+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:40.170+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:49:40.182+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:40.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:49:40.192+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:49:40.192+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:49:40.414+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.896 seconds
[2024-11-20T09:50:10.934+0700] {processor.py:186} INFO - Started process (PID=82556) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:10.938+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:50:10.943+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:10.940+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:11.186+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:11.238+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:11.238+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:50:11.300+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:11.300+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:50:11.306+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:11.305+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:50:11.310+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:11.310+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:50:11.313+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:11.313+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:50:11.369+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.460 seconds
[2024-11-20T09:50:41.762+0700] {processor.py:186} INFO - Started process (PID=82858) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:41.766+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:50:41.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:41.771+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:41.886+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:50:41.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:41.952+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:50:42.025+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:42.024+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:50:42.029+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:42.029+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:50:42.036+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:42.036+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:50:42.041+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:50:42.041+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:50:42.095+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.374 seconds
[2024-11-20T09:51:12.830+0700] {processor.py:186} INFO - Started process (PID=83182) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:12.832+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:51:12.837+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:12.835+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:12.950+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:12.997+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:12.996+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:51:13.048+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:13.048+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:51:13.053+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:13.052+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:51:13.055+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:13.055+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:51:13.057+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:13.057+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:51:13.105+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.299 seconds
[2024-11-20T09:51:43.324+0700] {processor.py:186} INFO - Started process (PID=83500) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:43.328+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:51:43.330+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.330+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:43.428+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:51:43.482+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.481+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:51:43.548+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.547+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:51:43.554+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.554+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:51:43.557+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.557+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:51:43.561+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:51:43.561+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:51:43.610+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.303 seconds
[2024-11-20T09:52:14.035+0700] {processor.py:186} INFO - Started process (PID=83895) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:14.037+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:52:14.040+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.039+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:14.149+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:14.222+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.221+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:52:14.301+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.301+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:52:14.309+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.308+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:52:14.312+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.312+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:52:14.315+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:14.315+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:52:14.364+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.345 seconds
[2024-11-20T09:52:45.386+0700] {processor.py:186} INFO - Started process (PID=84367) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:45.392+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:52:45.395+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.394+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:45.508+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:52:45.579+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.579+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:52:45.647+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.647+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:52:45.655+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.655+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:52:45.658+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.658+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:52:45.662+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:52:45.661+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:52:45.728+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.368 seconds
[2024-11-20T09:53:00.191+0700] {processor.py:186} INFO - Started process (PID=84703) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:00.192+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:53:00.201+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.200+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:00.332+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:00.885+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.884+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:53:00.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.953+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:53:00.961+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.960+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:53:00.965+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.965+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:53:00.968+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:00.967+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:53:01.014+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.835 seconds
[2024-11-20T09:53:16.176+0700] {processor.py:186} INFO - Started process (PID=85040) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:16.178+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:53:16.180+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.180+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:16.471+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:16.515+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.514+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:53:16.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.679+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:53:16.690+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.689+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:53:16.693+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.692+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:53:16.696+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:16.695+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:53:16.752+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.610 seconds
[2024-11-20T09:53:32.495+0700] {processor.py:186} INFO - Started process (PID=85350) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:32.499+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:53:32.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.506+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:32.686+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:32.743+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.743+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:53:32.824+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.820+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:53:32.842+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.838+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:53:32.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.849+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:53:32.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:32.857+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:53:33.001+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.525 seconds
[2024-11-20T09:53:55.475+0700] {processor.py:186} INFO - Started process (PID=85838) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:55.478+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:53:55.485+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.484+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:55.657+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:53:55.741+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.740+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:53:55.814+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.813+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:53:55.819+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.819+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:53:55.822+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.821+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:53:55.825+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:53:55.824+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:53:55.878+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.425 seconds
[2024-11-20T09:54:26.537+0700] {processor.py:186} INFO - Started process (PID=86165) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:26.540+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:54:26.546+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.545+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:26.662+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:26.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.717+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:54:26.778+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.777+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:54:26.784+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.783+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:54:26.788+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.787+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:54:26.792+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:26.792+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:54:26.859+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.339 seconds
[2024-11-20T09:54:57.703+0700] {processor.py:186} INFO - Started process (PID=86650) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:57.709+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:54:57.720+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:57.719+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:57.881+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:54:57.948+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:57.948+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:54:58.041+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:58.041+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:54:58.047+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:58.047+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:54:58.055+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:58.052+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:54:58.061+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:54:58.060+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:54:58.120+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.446 seconds
[2024-11-20T09:55:28.920+0700] {processor.py:186} INFO - Started process (PID=87129) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:55:28.929+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:55:28.936+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:28.935+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:55:29.038+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:55:29.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:29.123+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:55:29.292+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:29.291+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:55:29.310+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:29.309+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:55:29.315+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:29.315+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:55:29.320+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:29.319+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:55:29.395+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.499 seconds
[2024-11-20T09:55:59.858+0700] {processor.py:186} INFO - Started process (PID=87514) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:55:59.864+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:55:59.873+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:55:59.872+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:56:00.055+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:56:00.135+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:00.134+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:56:00.205+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:00.204+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:56:00.212+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:00.211+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:56:00.215+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:00.215+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:56:00.218+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:00.218+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:56:00.283+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.462 seconds
[2024-11-20T09:56:30.622+0700] {processor.py:186} INFO - Started process (PID=87962) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:56:30.627+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:56:30.638+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:30.636+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:56:30.884+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:56:30.983+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:30.983+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:56:31.039+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:31.038+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:56:31.043+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:31.043+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:56:31.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:31.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:56:31.048+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:56:31.048+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:56:31.093+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.504 seconds
[2024-11-20T09:57:01.115+0700] {processor.py:186} INFO - Started process (PID=88465) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:01.118+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:57:01.125+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.124+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:01.356+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:01.639+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.611+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:57:01.880+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.879+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:57:01.898+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.897+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:57:01.907+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.904+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:57:01.914+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:01.913+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:57:02.119+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.022 seconds
[2024-11-20T09:57:42.695+0700] {processor.py:186} INFO - Started process (PID=88908) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:42.697+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:57:42.703+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.702+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:42.809+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:57:42.875+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.874+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:57:42.967+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.966+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:57:42.975+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.974+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:57:42.978+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.978+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:57:42.982+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:57:42.981+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:57:43.051+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.375 seconds
[2024-11-20T09:58:13.954+0700] {processor.py:186} INFO - Started process (PID=89241) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:13.957+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:58:13.962+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:13.961+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:14.074+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:14.135+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:14.134+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:58:14.197+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:14.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:58:14.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:14.203+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:58:14.207+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:14.207+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:58:14.210+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:14.210+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:58:14.275+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.344 seconds
[2024-11-20T09:58:52.744+0700] {processor.py:186} INFO - Started process (PID=89866) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:52.751+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:58:52.769+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:52.764+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:52.933+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:58:53.039+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:53.038+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:58:53.121+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:53.120+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:58:53.135+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:53.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:58:53.141+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:53.141+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:58:53.145+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:58:53.145+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:58:53.240+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.559 seconds
[2024-11-20T09:59:23.731+0700] {processor.py:186} INFO - Started process (PID=90229) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:59:23.733+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T09:59:23.738+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:23.737+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:59:23.842+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T09:59:23.940+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:23.939+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T09:59:24.072+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:24.071+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T09:59:24.083+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:24.082+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T09:59:24.087+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:24.086+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T09:59:24.091+0700] {logging_mixin.py:190} INFO - [2024-11-20T09:59:24.090+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T09:59:24.208+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.490 seconds
[2024-11-20T10:00:11.212+0700] {processor.py:186} INFO - Started process (PID=90800) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:11.216+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:00:11.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.225+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:11.439+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:11.703+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.702+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:00:11.844+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.843+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:00:11.859+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.858+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:00:11.868+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.867+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:00:11.882+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:11.882+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:00:12.092+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.914 seconds
[2024-11-20T10:00:42.472+0700] {processor.py:186} INFO - Started process (PID=91190) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:42.478+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:00:42.490+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.489+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:42.623+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:00:42.678+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.677+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:00:42.729+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.729+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:00:42.735+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.735+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:00:42.737+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.737+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:00:42.740+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:00:42.740+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:00:42.794+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.343 seconds
[2024-11-20T10:01:13.511+0700] {processor.py:186} INFO - Started process (PID=91486) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:13.515+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:01:13.520+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.519+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:13.719+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:13.817+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.815+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:01:13.879+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.878+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:01:13.886+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.886+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:01:13.889+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.888+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:01:13.891+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:13.890+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:01:13.968+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.472 seconds
[2024-11-20T10:01:44.763+0700] {processor.py:186} INFO - Started process (PID=91803) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:44.767+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:01:44.774+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.773+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:44.862+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:01:44.906+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.906+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:01:44.959+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.958+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:01:44.965+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.965+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:01:44.967+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.967+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:01:44.970+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:01:44.969+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:01:45.029+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.282 seconds
[2024-11-20T10:02:15.147+0700] {processor.py:186} INFO - Started process (PID=92096) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:15.149+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:02:15.154+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.153+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:15.279+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:15.342+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.342+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:02:15.416+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.415+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:02:15.425+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.424+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:02:15.428+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.428+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:02:15.433+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:15.431+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:02:15.502+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.371 seconds
[2024-11-20T10:02:46.348+0700] {processor.py:186} INFO - Started process (PID=92405) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:46.351+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:02:46.357+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.356+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:46.480+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:02:46.541+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.540+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:02:46.604+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.603+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:02:46.611+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.611+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:02:46.615+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.614+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:02:46.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:02:46.617+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:02:46.683+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.351 seconds
[2024-11-20T10:03:22.385+0700] {processor.py:186} INFO - Started process (PID=92878) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:22.388+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:03:22.395+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:22.394+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:22.572+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:22.766+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:22.766+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:03:23.014+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:23.005+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:03:23.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:23.051+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:03:23.065+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:23.064+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:03:23.087+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:23.086+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:03:23.186+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.843 seconds
[2024-11-20T10:03:53.367+0700] {processor.py:186} INFO - Started process (PID=93248) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:53.372+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:03:53.380+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.379+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:53.505+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:03:53.557+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.556+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:03:53.614+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.614+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:03:53.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.621+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:03:53.623+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.623+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:03:53.625+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:03:53.625+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:03:53.677+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.334 seconds
[2024-11-20T10:04:47.939+0700] {processor.py:186} INFO - Started process (PID=93901) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:04:47.942+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:04:47.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:47.946+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:04:48.071+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:04:48.151+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:48.150+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:04:48.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:48.229+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:04:48.234+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:48.233+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:04:48.236+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:48.236+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:04:48.239+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:04:48.238+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:04:48.282+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.367 seconds
[2024-11-20T10:06:10.939+0700] {processor.py:186} INFO - Started process (PID=95034) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:10.944+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:06:10.951+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:10.950+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:11.102+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:11.548+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:11.548+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:06:11.613+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:11.612+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:06:11.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:11.618+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:06:11.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:11.620+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:06:11.624+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:11.623+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:06:11.667+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.748 seconds
[2024-11-20T10:06:42.281+0700] {processor.py:186} INFO - Started process (PID=95492) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:42.287+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:06:42.299+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.298+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:42.483+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:06:42.563+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.562+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:06:42.634+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.634+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:06:42.641+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.641+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:06:42.645+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.645+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:06:42.649+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:06:42.649+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:06:42.717+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.483 seconds
[2024-11-20T10:07:12.882+0700] {processor.py:186} INFO - Started process (PID=95875) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:07:12.888+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:07:12.902+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:12.902+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:07:13.171+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:07:13.290+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:13.290+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:07:13.399+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:13.399+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:07:13.407+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:13.407+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:07:13.412+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:13.411+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:07:13.421+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:07:13.421+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:07:13.494+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.683 seconds
[2024-11-20T10:08:00.845+0700] {processor.py:186} INFO - Started process (PID=96711) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:00.848+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:08:00.859+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:00.857+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:00.980+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:01.037+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:01.035+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:08:01.100+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:01.099+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:08:01.108+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:01.108+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:08:01.111+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:01.111+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:08:01.115+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:01.114+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:08:01.189+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.381 seconds
[2024-11-20T10:08:32.143+0700] {processor.py:186} INFO - Started process (PID=97162) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:32.146+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:08:32.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.155+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:32.293+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:08:32.366+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.365+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:08:32.431+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.430+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:08:32.442+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.442+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:08:32.452+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.451+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:08:32.455+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:08:32.455+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:08:32.519+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/.venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.407 seconds
[2024-11-20T10:11:35.317+0700] {processor.py:186} INFO - Started process (PID=99082) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:11:35.320+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:11:35.325+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.324+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:11:35.410+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:11:35.855+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.855+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:11:35.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.917+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:11:35.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:11:35.932+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.931+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:11:35.935+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:11:35.934+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:11:35.991+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.687 seconds
[2024-11-20T10:12:06.999+0700] {processor.py:186} INFO - Started process (PID=99541) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:07.001+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:12:07.014+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.013+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:07.233+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:07.418+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.418+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:12:07.643+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.642+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:12:07.674+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.671+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:12:07.691+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.691+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:12:07.698+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:07.698+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:12:07.835+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.862 seconds
[2024-11-20T10:12:38.591+0700] {processor.py:186} INFO - Started process (PID=99963) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:38.600+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:12:38.609+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:38.608+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:38.938+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:12:39.083+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:39.079+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:12:39.206+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:39.205+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:12:39.223+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:39.223+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:12:39.228+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:39.228+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:12:39.232+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:12:39.231+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:12:39.356+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.804 seconds
[2024-11-20T10:13:11.282+0700] {processor.py:186} INFO - Started process (PID=100683) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:11.287+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:13:11.296+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.295+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:11.484+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:11.596+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.594+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:13:11.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.718+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:13:11.741+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.740+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:13:11.746+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.745+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:13:11.760+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:11.759+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:13:11.868+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.609 seconds
[2024-11-20T10:13:42.529+0700] {processor.py:186} INFO - Started process (PID=101218) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:42.531+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:13:42.541+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:42.540+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:42.799+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:13:42.971+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:42.970+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:13:43.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:43.129+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:13:43.142+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:43.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:13:43.147+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:43.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:13:43.151+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:13:43.150+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:13:43.214+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.713 seconds
[2024-11-20T10:14:18.876+0700] {processor.py:186} INFO - Started process (PID=101873) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:18.879+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:14:18.885+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:18.884+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:19.048+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:19.127+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:19.126+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:14:19.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:19.228+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:14:19.238+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:19.237+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:14:19.244+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:19.244+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:14:19.250+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:19.250+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:14:19.326+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.479 seconds
[2024-11-20T10:14:50.401+0700] {processor.py:186} INFO - Started process (PID=102428) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:50.407+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:14:50.436+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.434+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:50.543+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:14:50.597+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.597+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:14:50.652+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.652+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:14:50.661+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.661+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:14:50.665+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.664+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:14:50.668+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:14:50.667+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:14:50.764+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.415 seconds
[2024-11-20T10:15:21.681+0700] {processor.py:186} INFO - Started process (PID=103216) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:21.698+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:15:21.709+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:21.707+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:21.942+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:22.027+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:22.026+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:15:22.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:22.119+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:15:22.141+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:22.140+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:15:22.144+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:22.144+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:15:22.147+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:22.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:15:22.237+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.601 seconds
[2024-11-20T10:15:52.897+0700] {processor.py:186} INFO - Started process (PID=103757) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:52.903+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:15:52.915+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:52.913+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:53.095+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:15:53.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:53.156+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:15:53.242+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:53.241+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:15:53.251+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:53.251+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:15:53.255+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:53.254+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:15:53.258+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:15:53.258+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:15:53.320+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.470 seconds
[2024-11-20T10:16:23.420+0700] {processor.py:186} INFO - Started process (PID=104057) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:23.422+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:16:23.430+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.429+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:23.543+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:23.605+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.604+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:16:23.695+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.694+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:16:23.704+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.703+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:16:23.709+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.708+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:16:23.713+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:23.712+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:16:23.774+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.370 seconds
[2024-11-20T10:16:54.013+0700] {processor.py:186} INFO - Started process (PID=104429) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:54.016+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:16:54.025+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.023+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:54.187+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:16:54.267+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.267+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:16:54.365+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.364+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:16:54.376+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.375+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:16:54.382+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.381+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:16:54.387+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:16:54.386+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:16:54.513+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.525 seconds
[2024-11-20T10:17:24.711+0700] {processor.py:186} INFO - Started process (PID=104728) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:24.713+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:17:24.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:24.718+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:24.844+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:24.940+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:24.939+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:17:25.051+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:25.050+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:17:25.062+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:25.062+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:17:25.068+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:25.067+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:17:25.074+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:25.073+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:17:25.193+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.497 seconds
[2024-11-20T10:17:55.989+0700] {processor.py:186} INFO - Started process (PID=105059) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:55.991+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:17:55.995+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:55.994+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:56.107+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:17:56.166+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:56.165+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:17:56.230+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:56.229+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:17:56.236+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:56.235+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:17:56.241+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:56.240+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:17:56.245+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:17:56.244+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:17:56.586+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.609 seconds
[2024-11-20T10:18:27.138+0700] {processor.py:186} INFO - Started process (PID=105360) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:27.142+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:18:27.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.152+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:27.313+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:27.360+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.360+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:18:27.404+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:18:27.408+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.408+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:18:27.411+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.410+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:18:27.413+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:27.413+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:18:27.461+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.360 seconds
[2024-11-20T10:18:57.674+0700] {processor.py:186} INFO - Started process (PID=105656) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:57.676+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:18:57.681+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.681+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:57.773+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:18:57.822+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.822+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:18:57.887+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.886+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:18:57.894+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.894+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:18:57.898+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.898+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:18:57.901+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:18:57.901+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:18:57.970+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.310 seconds
[2024-11-20T10:19:28.256+0700] {processor.py:186} INFO - Started process (PID=106124) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:28.259+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:19:28.269+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.268+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:28.439+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:28.526+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.526+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:19:28.857+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.856+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:19:28.862+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.862+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:19:28.865+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.865+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:19:28.868+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:28.868+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:19:28.910+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.677 seconds
[2024-11-20T10:19:59.268+0700] {processor.py:186} INFO - Started process (PID=106413) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:59.274+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:19:59.282+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.281+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:59.394+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:19:59.440+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.440+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:19:59.492+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.491+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:19:59.496+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.496+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:19:59.499+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.498+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:19:59.501+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:19:59.501+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:19:59.776+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.537 seconds
[2024-11-20T10:20:29.940+0700] {processor.py:186} INFO - Started process (PID=106907) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:20:29.944+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:20:29.954+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:29.953+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:20:30.217+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:20:30.321+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:30.320+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:20:30.408+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:30.407+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:20:30.426+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:30.425+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:20:30.434+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:30.433+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:20:30.440+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:20:30.439+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:20:30.554+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.647 seconds
[2024-11-20T10:21:00.919+0700] {processor.py:186} INFO - Started process (PID=107236) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:00.922+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:21:00.929+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:00.928+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:01.045+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:01.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:01.130+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:21:01.206+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:01.206+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:21:01.215+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:01.214+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:21:01.222+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:01.222+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:21:01.226+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:01.225+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:21:01.299+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.402 seconds
[2024-11-20T10:21:31.932+0700] {processor.py:186} INFO - Started process (PID=107759) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:31.934+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:21:31.948+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:31.948+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:32.062+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:21:32.116+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:32.116+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:21:32.178+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:32.178+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:21:32.185+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:32.184+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:21:32.188+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:32.187+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:21:32.190+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:21:32.190+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:21:32.242+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.326 seconds
[2024-11-20T10:22:03.186+0700] {processor.py:186} INFO - Started process (PID=108086) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:03.188+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:22:03.194+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.193+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:03.328+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:03.386+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.385+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:22:03.472+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.471+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:22:03.482+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.481+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:22:03.489+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.488+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:22:03.498+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:03.496+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:22:03.586+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.417 seconds
[2024-11-20T10:22:35.390+0700] {processor.py:186} INFO - Started process (PID=108485) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:35.399+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:22:35.417+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:35.416+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:35.709+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:22:36.033+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:36.033+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:22:36.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:36.203+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:22:36.224+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:36.221+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:22:36.234+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:36.234+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:22:36.242+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:22:36.242+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:22:36.341+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.003 seconds
[2024-11-20T10:23:06.995+0700] {processor.py:186} INFO - Started process (PID=108833) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:06.996+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:23:07.002+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.001+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:07.089+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:07.149+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.148+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:23:07.206+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.205+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:23:07.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.210+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:23:07.213+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.213+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:23:07.216+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:07.215+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:23:07.281+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.303 seconds
[2024-11-20T10:23:37.933+0700] {processor.py:186} INFO - Started process (PID=109136) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:37.936+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:23:37.950+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:37.947+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:38.164+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:23:38.245+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:38.245+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:23:38.375+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:38.374+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:23:38.397+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:38.395+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:23:38.402+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:38.402+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:23:38.406+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:23:38.406+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:23:38.493+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.590 seconds
[2024-11-20T10:24:08.607+0700] {processor.py:186} INFO - Started process (PID=109467) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:08.609+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:24:08.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.616+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:08.743+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:08.805+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.804+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:24:08.913+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.913+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:24:08.923+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.922+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:24:08.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:24:08.929+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:08.928+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:24:09.006+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.420 seconds
[2024-11-20T10:24:40.512+0700] {processor.py:186} INFO - Started process (PID=109821) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:40.522+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:24:40.528+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:40.527+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:40.706+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:24:40.868+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:40.867+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:24:41.002+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:41.001+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:24:41.009+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:41.008+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:24:41.013+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:41.012+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:24:41.017+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:24:41.017+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:24:41.091+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.629 seconds
[2024-11-20T10:25:00.492+0700] {processor.py:186} INFO - Started process (PID=110134) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:00.494+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:25:00.498+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.498+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:00.603+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:00.669+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.668+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:25:00.730+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.729+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:25:00.736+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.736+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:25:00.740+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.739+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:25:00.743+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:00.742+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:25:00.805+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.326 seconds
[2024-11-20T10:25:32.918+0700] {processor.py:186} INFO - Started process (PID=110702) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:32.920+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:25:32.925+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:32.924+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:33.026+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:25:33.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:33.076+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:25:33.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:33.124+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:25:33.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:33.131+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:25:33.135+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:33.135+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:25:33.138+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:25:33.138+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:25:33.190+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.287 seconds
[2024-11-20T10:26:04.987+0700] {processor.py:186} INFO - Started process (PID=111391) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:04.990+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:26:04.999+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:04.998+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:05.143+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:05.227+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:05.226+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:26:05.372+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:05.371+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:26:05.383+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:05.383+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:26:05.390+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:05.390+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:26:05.395+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:05.395+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:26:05.517+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.565 seconds
[2024-11-20T10:26:35.750+0700] {processor.py:186} INFO - Started process (PID=111854) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:35.760+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:26:35.800+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:35.794+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:36.082+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:26:36.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:36.214+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:26:36.278+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:36.277+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:26:36.283+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:36.282+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:26:36.286+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:36.286+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:26:36.289+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:26:36.288+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:26:36.338+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.641 seconds
[2024-11-20T10:27:06.902+0700] {processor.py:186} INFO - Started process (PID=112277) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:06.906+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:27:06.916+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:06.915+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:07.047+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:07.111+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:07.110+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:27:07.190+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:07.189+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:27:07.197+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:07.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:27:07.201+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:07.200+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:27:07.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:07.204+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:27:07.281+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.400 seconds
[2024-11-20T10:27:37.489+0700] {processor.py:186} INFO - Started process (PID=112571) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:37.491+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:27:37.497+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.496+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:37.631+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:27:37.736+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.735+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:27:37.848+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.847+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:27:37.854+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.854+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:27:37.860+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.860+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:27:37.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:27:37.864+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:27:37.941+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.468 seconds
[2024-11-20T10:28:09.887+0700] {processor.py:186} INFO - Started process (PID=113018) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:09.890+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:28:09.897+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:09.897+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:10.050+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:10.121+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:10.120+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:28:10.183+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:10.183+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:28:10.188+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:10.188+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:28:10.191+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:10.191+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:28:10.195+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:10.194+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:28:10.242+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.383 seconds
[2024-11-20T10:28:41.342+0700] {processor.py:186} INFO - Started process (PID=113552) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:41.346+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:28:41.355+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.354+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:41.495+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:28:41.580+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.580+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:28:41.674+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.674+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:28:41.686+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.685+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:28:41.689+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.688+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:28:41.694+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:28:41.693+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:28:41.768+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.448 seconds
[2024-11-20T10:29:12.353+0700] {processor.py:186} INFO - Started process (PID=114069) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:12.357+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:29:12.364+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.363+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:12.504+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:12.599+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.599+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:29:12.682+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.682+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:29:12.690+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.690+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:29:12.697+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.697+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:29:12.704+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:12.703+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:29:12.789+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.453 seconds
[2024-11-20T10:29:42.914+0700] {processor.py:186} INFO - Started process (PID=114587) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:42.917+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:29:42.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:42.920+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:43.017+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:29:43.075+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:43.075+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:29:43.127+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:43.126+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:29:43.133+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:43.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:29:43.136+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:43.136+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:29:43.141+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:29:43.141+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:29:43.193+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.295 seconds
[2024-11-20T10:30:13.502+0700] {processor.py:186} INFO - Started process (PID=114919) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:13.506+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:30:13.513+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.512+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:13.629+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:13.720+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.720+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:30:13.783+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.783+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:30:13.792+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.792+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:30:13.795+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.794+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:30:13.797+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:13.797+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:30:13.848+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.364 seconds
[2024-11-20T10:30:44.380+0700] {processor.py:186} INFO - Started process (PID=115346) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:44.382+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:30:44.387+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.386+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:44.498+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:30:44.603+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.603+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:30:44.709+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.708+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:30:44.714+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.714+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:30:44.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.717+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:30:44.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:30:44.720+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:30:44.792+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.430 seconds
[2024-11-20T10:31:15.816+0700] {processor.py:186} INFO - Started process (PID=115866) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:15.820+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:31:15.825+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:15.824+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:15.946+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:16.009+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:16.009+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:31:16.077+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:16.077+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:31:16.083+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:16.082+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:31:16.086+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:16.086+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:31:16.089+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:16.089+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:31:16.141+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.342 seconds
[2024-11-20T10:31:47.043+0700] {processor.py:186} INFO - Started process (PID=116229) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:47.046+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:31:47.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.053+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:47.162+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:31:47.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.213+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:31:47.287+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.287+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:31:47.293+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.292+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:31:47.295+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.294+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:31:47.297+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:31:47.296+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:31:47.654+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.632 seconds
[2024-11-20T10:32:18.947+0700] {processor.py:186} INFO - Started process (PID=116558) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:32:18.951+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:32:18.969+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:18.967+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:32:19.102+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:32:19.239+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:19.238+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:32:19.354+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:19.353+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:32:19.364+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:19.359+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:32:19.370+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:19.369+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:32:19.377+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:32:19.376+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:32:19.489+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.582 seconds
[2024-11-20T10:33:07.842+0700] {processor.py:186} INFO - Started process (PID=117161) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:07.844+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:33:07.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:07.849+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:07.949+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:08.019+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:08.018+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:33:08.069+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:08.068+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:33:08.074+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:08.073+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:33:08.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:08.076+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:33:08.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:08.078+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:33:08.117+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.287 seconds
[2024-11-20T10:33:38.526+0700] {processor.py:186} INFO - Started process (PID=117527) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:38.528+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:33:38.533+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.533+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:38.617+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:33:38.673+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.672+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:33:38.714+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.714+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:33:38.719+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.719+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:33:38.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.721+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:33:38.723+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:33:38.723+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:33:38.768+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.256 seconds
[2024-11-20T10:34:11.524+0700] {processor.py:186} INFO - Started process (PID=118256) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:11.531+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:34:11.549+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:11.545+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:11.856+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:11.957+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:11.957+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:34:12.065+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:12.065+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:34:12.070+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:12.070+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:34:12.092+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:12.091+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:34:12.112+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:12.112+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:34:12.242+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.754 seconds
[2024-11-20T10:34:42.385+0700] {processor.py:186} INFO - Started process (PID=118826) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:42.390+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:34:42.395+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.394+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:42.513+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:34:42.582+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.581+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:34:42.667+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.666+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:34:42.676+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.676+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:34:42.681+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.680+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:34:42.685+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:34:42.684+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:34:42.798+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.435 seconds
[2024-11-20T10:35:13.309+0700] {processor.py:186} INFO - Started process (PID=119344) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:13.311+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:35:13.316+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.316+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:13.454+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:13.506+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.505+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:35:13.573+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.573+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:35:13.585+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.585+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:35:13.593+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.592+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:35:13.611+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:13.610+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:35:13.727+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.436 seconds
[2024-11-20T10:35:43.816+0700] {processor.py:186} INFO - Started process (PID=119681) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:43.820+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:35:43.824+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:43.824+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:43.923+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:35:43.977+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:43.976+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:35:44.034+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:44.034+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:35:44.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:44.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:35:44.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:44.049+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:35:44.059+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:35:44.058+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:35:44.140+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.339 seconds
[2024-11-20T10:36:14.978+0700] {processor.py:186} INFO - Started process (PID=120052) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:14.980+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:36:14.984+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:14.984+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:15.084+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:15.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:15.124+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:36:15.171+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:15.171+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:36:15.177+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:15.176+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:36:15.179+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:15.178+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:36:15.181+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:15.180+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:36:15.221+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.257 seconds
[2024-11-20T10:36:45.920+0700] {processor.py:186} INFO - Started process (PID=120652) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:45.922+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:36:45.927+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:45.927+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:46.033+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:36:46.082+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:46.081+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:36:46.134+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:46.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:36:46.140+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:46.139+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:36:46.143+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:46.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:36:46.146+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:36:46.145+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:36:46.195+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.289 seconds
[2024-11-20T10:37:16.829+0700] {processor.py:186} INFO - Started process (PID=120969) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:16.834+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:37:16.840+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:16.839+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:16.965+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:17.039+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:17.038+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:37:17.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:17.106+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:37:17.127+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:17.127+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:37:17.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:17.131+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:37:17.136+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:17.136+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:37:17.206+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.393 seconds
[2024-11-20T10:37:48.546+0700] {processor.py:186} INFO - Started process (PID=121861) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:48.552+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:37:48.559+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.558+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:48.680+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:37:48.760+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.759+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:37:48.834+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.834+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:37:48.839+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.839+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:37:48.848+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.847+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:37:48.851+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:37:48.850+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:37:48.909+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.399 seconds
[2024-11-20T10:38:23.812+0700] {processor.py:186} INFO - Started process (PID=123152) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:23.820+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:38:23.828+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:23.826+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:24.002+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:24.078+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:24.077+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:38:24.143+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:24.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:38:24.148+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:24.148+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:38:24.150+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:24.150+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:38:24.153+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:24.152+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:38:24.195+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.415 seconds
[2024-11-20T10:38:55.784+0700] {processor.py:186} INFO - Started process (PID=123972) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:55.813+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:38:55.818+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:55.817+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:55.931+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:38:56.008+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:56.008+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:38:56.086+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:56.086+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:38:56.104+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:56.104+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:38:56.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:56.107+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:38:56.119+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:38:56.118+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:38:56.264+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.493 seconds
[2024-11-20T10:39:55.937+0700] {processor.py:186} INFO - Started process (PID=125561) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:39:55.939+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:39:55.944+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:55.944+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:39:56.109+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:39:56.158+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:56.157+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:39:56.224+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:56.223+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:39:56.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:56.229+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:39:56.234+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:56.233+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:39:56.237+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:39:56.236+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:39:56.301+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.381 seconds
[2024-11-20T10:40:24.369+0700] {processor.py:186} INFO - Started process (PID=126077) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:24.370+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:40:24.375+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.375+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:24.468+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:24.531+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.530+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:40:24.575+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.575+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:40:24.580+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.580+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:40:24.582+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.582+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:40:24.585+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:24.585+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:40:24.646+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.289 seconds
[2024-11-20T10:40:55.488+0700] {processor.py:186} INFO - Started process (PID=126658) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:55.491+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:40:55.496+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.495+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:55.678+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:40:55.829+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.829+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:40:55.978+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.973+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:40:55.985+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.985+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:40:55.990+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.990+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:40:55.998+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:40:55.997+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:40:56.080+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.620 seconds
[2024-11-20T10:41:26.336+0700] {processor.py:186} INFO - Started process (PID=127802) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:26.339+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:41:26.344+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.343+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:26.504+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:26.573+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.572+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:41:26.635+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.634+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:41:26.640+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.639+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:41:26.643+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.642+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:41:26.645+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:26.645+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:41:26.718+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.407 seconds
[2024-11-20T10:41:57.643+0700] {processor.py:186} INFO - Started process (PID=128181) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:57.645+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:41:57.651+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.650+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:57.819+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:41:57.878+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.878+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:41:57.941+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.940+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:41:57.946+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:41:57.949+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.949+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:41:57.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:41:57.952+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:41:58.003+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.468 seconds
[2024-11-20T10:42:32.231+0700] {processor.py:186} INFO - Started process (PID=128780) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:42:32.246+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:42:32.256+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.255+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:42:32.486+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:42:32.593+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.592+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:42:32.689+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.688+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:42:32.699+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.698+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:42:32.704+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.703+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:42:32.710+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:42:32.709+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:42:32.900+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.711 seconds
[2024-11-20T10:43:03.707+0700] {processor.py:186} INFO - Started process (PID=129262) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:03.710+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:43:03.716+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.715+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:03.801+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:03.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.849+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:43:03.910+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.910+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:43:03.920+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.919+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:43:03.923+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.922+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:43:03.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:03.929+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:43:04.067+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.389 seconds
[2024-11-20T10:43:34.431+0700] {processor.py:186} INFO - Started process (PID=129564) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:34.433+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:43:34.438+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.437+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:34.545+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:43:34.631+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.630+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:43:34.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.683+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:43:34.689+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.689+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:43:34.693+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.693+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:43:34.697+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:43:34.697+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:43:34.764+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.348 seconds
[2024-11-20T10:44:07.597+0700] {processor.py:186} INFO - Started process (PID=129975) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:07.607+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:44:07.642+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:07.630+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:07.942+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:08.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:08.074+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:44:08.169+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:08.168+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:44:08.181+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:08.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:44:08.186+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:08.186+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:44:08.193+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:08.192+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:44:08.277+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.738 seconds
[2024-11-20T10:44:38.943+0700] {processor.py:186} INFO - Started process (PID=130389) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:38.948+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:44:38.954+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:38.953+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:39.087+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:44:39.147+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:39.147+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:44:39.215+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:39.214+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:44:39.221+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:39.221+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:44:39.225+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:39.224+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:44:39.230+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:44:39.229+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:44:39.287+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.364 seconds
[2024-11-20T10:45:09.497+0700] {processor.py:186} INFO - Started process (PID=130686) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:09.504+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:45:09.515+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.513+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:09.722+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:09.806+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.805+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:45:09.906+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.905+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:45:09.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.916+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:45:09.922+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.921+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:45:09.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:09.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:45:10.035+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.567 seconds
[2024-11-20T10:45:40.184+0700] {processor.py:186} INFO - Started process (PID=131031) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:40.189+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:45:40.200+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.198+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:40.442+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:45:40.558+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.556+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:45:40.738+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.737+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:45:40.763+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.759+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:45:40.776+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.775+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:45:40.785+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:45:40.785+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:45:40.861+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.711 seconds
[2024-11-20T10:46:11.033+0700] {processor.py:186} INFO - Started process (PID=131533) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:11.041+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:46:11.061+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.060+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:11.279+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:11.352+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.351+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:46:11.540+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.540+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:46:11.555+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.554+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:46:11.558+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.557+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:46:11.567+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:11.567+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:46:11.663+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.683 seconds
[2024-11-20T10:46:43.529+0700] {processor.py:186} INFO - Started process (PID=132556) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:43.534+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:46:43.539+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:43.538+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:43.680+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:46:43.746+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:43.745+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:46:44.205+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:44.205+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:46:44.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:44.211+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:46:44.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:44.214+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:46:44.220+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:46:44.219+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:46:44.281+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.772 seconds
[2024-11-20T10:47:14.745+0700] {processor.py:186} INFO - Started process (PID=132900) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:14.747+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:47:14.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:14.751+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:14.886+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:15.070+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:15.070+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:47:15.145+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:15.145+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:47:15.152+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:15.152+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:47:15.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:15.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:47:15.160+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:15.159+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:47:15.563+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.834 seconds
[2024-11-20T10:47:45.643+0700] {processor.py:186} INFO - Started process (PID=133289) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:45.646+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:47:45.649+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.649+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:45.749+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:47:45.811+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.811+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:47:45.873+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.873+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:47:45.878+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.878+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:47:45.882+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.881+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:47:45.885+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:47:45.884+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:47:45.942+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.312 seconds
[2024-11-20T10:48:16.480+0700] {processor.py:186} INFO - Started process (PID=133747) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:16.482+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:48:16.487+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.486+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:16.627+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:16.709+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.708+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:48:16.779+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.775+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:48:16.784+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.784+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:48:16.787+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.786+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:48:16.790+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:16.789+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:48:16.844+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.382 seconds
[2024-11-20T10:48:47.233+0700] {processor.py:186} INFO - Started process (PID=134046) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:47.237+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:48:47.245+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.244+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:47.363+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:48:47.684+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.683+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:48:47.741+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.740+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:48:47.748+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.747+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:48:47.752+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.752+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:48:47.755+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:48:47.754+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:48:47.812+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.595 seconds
[2024-11-20T10:49:19.380+0700] {processor.py:186} INFO - Started process (PID=134349) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:19.383+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:49:19.393+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:19.391+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:19.622+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:20.072+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:20.070+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:49:20.302+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:20.298+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:49:20.314+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:20.313+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:49:20.321+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:20.320+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:49:20.339+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:20.338+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:49:20.453+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.103 seconds
[2024-11-20T10:49:50.791+0700] {processor.py:186} INFO - Started process (PID=134656) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:50.795+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:49:50.805+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:50.803+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:50.973+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:49:51.071+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:51.070+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:49:51.182+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:51.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:49:51.192+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:51.192+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:49:51.198+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:51.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:49:51.203+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:49:51.202+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:49:51.297+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.528 seconds
[2024-11-20T10:50:21.702+0700] {processor.py:186} INFO - Started process (PID=134968) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:21.705+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:50:21.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:21.710+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:21.889+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:21.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:21.962+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:50:22.050+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:22.049+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:50:22.060+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:22.060+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:50:22.063+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:22.062+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:50:22.066+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:22.065+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:50:22.153+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.470 seconds
[2024-11-20T10:50:52.347+0700] {processor.py:186} INFO - Started process (PID=135287) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:52.355+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:50:52.360+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.360+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:52.594+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:50:52.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.679+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:50:52.797+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.796+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:50:52.804+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.804+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:50:52.807+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.807+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:50:52.816+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:50:52.816+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:50:52.880+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.554 seconds
[2024-11-20T10:51:23.619+0700] {processor.py:186} INFO - Started process (PID=135585) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:23.622+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:51:23.635+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.633+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:23.812+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:23.899+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.898+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:51:23.970+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.969+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:51:23.978+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.977+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:51:23.983+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.981+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:51:23.986+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:23.986+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:51:24.068+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.504 seconds
[2024-11-20T10:51:54.381+0700] {processor.py:186} INFO - Started process (PID=135886) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:54.383+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:51:54.399+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.398+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:54.577+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:51:54.653+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.652+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:51:54.755+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.754+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:51:54.764+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.763+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:51:54.769+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.769+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:51:54.775+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:51:54.774+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:51:54.850+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.505 seconds
[2024-11-20T10:52:25.246+0700] {processor.py:186} INFO - Started process (PID=136180) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:25.250+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:52:25.258+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.257+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:25.423+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:25.495+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.494+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:52:25.578+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.577+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:52:25.585+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.585+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:52:25.590+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.589+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:52:25.594+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:25.594+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:52:25.668+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.448 seconds
[2024-11-20T10:52:56.199+0700] {processor.py:186} INFO - Started process (PID=136482) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:56.205+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:52:56.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.210+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:56.391+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:52:56.452+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.451+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:52:56.532+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.531+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:52:56.538+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.537+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:52:56.540+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.540+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:52:56.542+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:52:56.542+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:52:56.610+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.432 seconds
[2024-11-20T10:53:26.830+0700] {processor.py:186} INFO - Started process (PID=136782) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:26.834+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:53:26.838+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:26.837+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:26.931+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:26.985+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:26.984+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:53:27.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:27.053+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:53:27.059+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:27.058+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:53:27.064+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:27.063+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:53:27.067+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:27.067+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:53:27.130+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.338 seconds
[2024-11-20T10:53:57.900+0700] {processor.py:186} INFO - Started process (PID=137144) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:57.910+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:53:57.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:57.915+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:58.038+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:53:58.084+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:58.084+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:53:58.147+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:58.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:53:58.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:58.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:53:58.159+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:58.159+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:53:58.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:53:58.161+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:53:58.811+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.980 seconds
[2024-11-20T10:54:29.229+0700] {processor.py:186} INFO - Started process (PID=137446) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:54:29.231+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:54:29.235+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.235+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:54:29.378+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:54:29.446+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.445+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:54:29.516+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.516+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:54:29.523+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.522+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:54:29.526+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.525+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:54:29.528+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:29.528+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:54:29.576+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.360 seconds
[2024-11-20T10:54:59.829+0700] {processor.py:186} INFO - Started process (PID=137739) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:54:59.832+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:54:59.840+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:54:59.838+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:54:59.978+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:55:00.074+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:00.073+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:55:00.178+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:00.177+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:55:00.193+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:00.193+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:55:00.197+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:00.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:55:00.200+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:00.200+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:55:00.279+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.505 seconds
[2024-11-20T10:55:30.515+0700] {processor.py:186} INFO - Started process (PID=138117) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:55:30.522+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:55:30.528+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.527+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:55:30.675+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:55:30.747+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.746+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:55:30.813+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.813+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:55:30.827+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.827+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:55:30.831+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.831+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:55:30.834+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:55:30.834+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:55:30.910+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.414 seconds
[2024-11-20T10:56:01.738+0700] {processor.py:186} INFO - Started process (PID=138412) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:01.744+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:56:01.758+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:01.755+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:01.887+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:01.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:01.963+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:56:02.033+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:02.032+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:56:02.038+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:02.038+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:56:02.042+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:02.042+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:56:02.048+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:02.046+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:56:02.150+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.457 seconds
[2024-11-20T10:56:32.764+0700] {processor.py:186} INFO - Started process (PID=138713) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:32.768+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:56:32.774+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:32.773+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:32.950+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:56:33.043+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:33.042+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:56:33.125+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:33.124+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:56:33.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:33.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:56:33.140+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:33.138+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:56:33.144+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:56:33.143+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:56:33.226+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.502 seconds
[2024-11-20T10:57:03.690+0700] {processor.py:186} INFO - Started process (PID=139008) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:03.692+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:57:03.698+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:03.696+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:03.863+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:03.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:03.929+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:57:04.007+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:04.007+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:57:04.015+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:04.014+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:57:04.020+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:04.019+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:57:04.023+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:04.022+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:57:04.089+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.422 seconds
[2024-11-20T10:57:34.509+0700] {processor.py:186} INFO - Started process (PID=139311) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:34.513+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:57:34.520+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.519+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:34.688+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:57:34.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.750+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:57:34.818+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.817+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:57:34.826+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.825+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:57:34.831+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.830+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:57:34.835+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:57:34.834+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:57:34.901+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.425 seconds
[2024-11-20T10:58:05.341+0700] {processor.py:186} INFO - Started process (PID=139634) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:05.344+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:58:05.352+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.351+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:05.495+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:05.560+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.559+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:58:05.631+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.631+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:58:05.638+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.638+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:58:05.641+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.641+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:58:05.644+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:05.644+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:58:05.697+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.412 seconds
[2024-11-20T10:58:36.198+0700] {processor.py:186} INFO - Started process (PID=139930) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:36.202+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:58:36.209+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.208+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:36.304+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:58:36.371+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.371+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:58:36.459+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.459+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:58:36.468+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.468+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:58:36.473+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.472+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:58:36.478+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:58:36.478+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:58:36.540+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.355 seconds
[2024-11-20T10:59:06.827+0700] {processor.py:186} INFO - Started process (PID=140249) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:06.830+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:59:06.837+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:06.836+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:06.957+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:07.023+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:07.022+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:59:07.091+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:07.090+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:59:07.101+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:07.101+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:59:07.104+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:07.104+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:59:07.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:07.107+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:59:07.169+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.359 seconds
[2024-11-20T10:59:37.532+0700] {processor.py:186} INFO - Started process (PID=140732) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:37.539+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T10:59:37.547+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.546+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:37.694+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T10:59:37.767+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.766+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T10:59:37.832+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.832+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T10:59:37.842+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.841+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T10:59:37.845+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.844+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T10:59:37.848+0700] {logging_mixin.py:190} INFO - [2024-11-20T10:59:37.847+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T10:59:37.923+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.409 seconds
[2024-11-20T11:00:08.383+0700] {processor.py:186} INFO - Started process (PID=141225) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:08.391+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:00:08.402+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.401+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:08.594+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:08.704+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.703+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:00:08.860+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.853+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:00:08.867+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.866+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:00:08.871+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.870+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:00:08.874+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:08.874+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:00:09.006+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.659 seconds
[2024-11-20T11:00:39.402+0700] {processor.py:186} INFO - Started process (PID=142262) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:39.408+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:00:39.416+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.415+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:39.612+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:00:39.708+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.708+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:00:39.915+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.914+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:00:39.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.930+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:00:39.940+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.940+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:00:39.954+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:00:39.953+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:00:40.046+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.704 seconds
[2024-11-20T11:01:10.392+0700] {processor.py:186} INFO - Started process (PID=142583) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:10.396+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:01:10.405+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.404+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:10.506+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:10.551+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.550+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:01:10.605+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.604+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:01:10.611+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.611+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:01:10.616+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.615+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:01:10.619+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:10.619+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:01:10.672+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.315 seconds
[2024-11-20T11:01:41.060+0700] {processor.py:186} INFO - Started process (PID=143639) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:41.065+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:01:41.071+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.070+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:41.221+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:01:41.291+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.291+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:01:41.373+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.373+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:01:41.381+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.381+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:01:41.383+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.383+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:01:41.386+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:01:41.385+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:01:41.463+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.426 seconds
[2024-11-20T11:02:12.051+0700] {processor.py:186} INFO - Started process (PID=144120) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:12.058+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:02:12.068+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.066+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:12.290+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:12.439+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.438+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:02:12.603+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.602+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:02:12.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.618+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:02:12.622+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.622+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:02:12.632+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:12.631+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:02:12.767+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.752 seconds
[2024-11-20T11:02:43.223+0700] {processor.py:186} INFO - Started process (PID=144539) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:43.225+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:02:43.241+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.236+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:43.453+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:02:43.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.510+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:02:43.576+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.576+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:02:43.583+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.582+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:02:43.587+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.586+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:02:43.592+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:02:43.592+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:02:43.697+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.525 seconds
[2024-11-20T11:03:13.995+0700] {processor.py:186} INFO - Started process (PID=145110) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:13.997+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:03:14.002+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.001+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:14.130+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:14.231+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.230+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:03:14.309+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.309+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:03:14.316+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.316+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:03:14.321+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.319+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:03:14.326+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:14.326+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:03:14.420+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.440 seconds
[2024-11-20T11:03:44.874+0700] {processor.py:186} INFO - Started process (PID=145628) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:44.877+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:03:44.882+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:44.881+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:45.046+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:03:45.136+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:45.131+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:03:45.272+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:45.270+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:03:45.279+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:45.279+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:03:45.286+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:45.285+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:03:45.293+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:03:45.293+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:03:45.439+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.586 seconds
[2024-11-20T11:04:15.831+0700] {processor.py:186} INFO - Started process (PID=146151) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:15.835+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:04:15.841+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:15.840+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:15.949+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:16.006+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:16.005+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:04:16.084+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:16.084+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:04:16.094+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:16.094+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:04:16.100+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:16.099+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:04:16.103+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:16.102+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:04:16.160+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.345 seconds
[2024-11-20T11:04:46.537+0700] {processor.py:186} INFO - Started process (PID=146453) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:46.542+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:04:46.554+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.552+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:46.670+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:04:46.716+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.716+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:04:46.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.771+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:04:46.781+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.780+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:04:46.787+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.787+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:04:46.790+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:04:46.790+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:04:46.851+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.354 seconds
[2024-11-20T11:05:17.490+0700] {processor.py:186} INFO - Started process (PID=146753) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:17.498+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:05:17.514+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.513+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:17.721+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:17.797+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.796+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:05:17.854+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.853+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:05:17.859+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.859+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:05:17.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.863+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:05:17.867+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:17.866+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:05:17.912+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.503 seconds
[2024-11-20T11:05:48.778+0700] {processor.py:186} INFO - Started process (PID=147061) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:48.781+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:05:48.785+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:48.784+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:48.889+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:05:48.937+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:48.937+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:05:48.992+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:48.992+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:05:48.998+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:48.997+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:05:49.001+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:49.000+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:05:49.004+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:05:49.003+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:05:49.062+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.300 seconds
[2024-11-20T11:06:19.206+0700] {processor.py:186} INFO - Started process (PID=147354) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:19.208+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:06:19.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.212+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:19.314+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:19.381+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.380+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:06:19.469+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.469+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:06:19.500+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.500+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:06:19.505+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.504+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:06:19.517+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:19.517+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:06:19.573+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.383 seconds
[2024-11-20T11:06:50.032+0700] {processor.py:186} INFO - Started process (PID=148300) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:50.034+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:06:50.039+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.038+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:50.236+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:06:50.352+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.351+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:06:50.520+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.519+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:06:50.540+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.539+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:06:50.549+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.548+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:06:50.564+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:06:50.563+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:06:50.711+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.700 seconds
[2024-11-20T11:07:21.048+0700] {processor.py:186} INFO - Started process (PID=148622) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:21.053+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:07:21.061+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.060+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:21.196+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:21.324+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.323+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:07:21.384+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.383+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:07:21.392+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.392+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:07:21.395+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.394+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:07:21.397+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:21.397+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:07:21.449+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.418 seconds
[2024-11-20T11:07:51.688+0700] {processor.py:186} INFO - Started process (PID=149043) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:51.691+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:07:51.699+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.698+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:51.814+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:07:51.861+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.860+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:07:51.919+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.917+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:07:51.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:07:51.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.929+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:07:51.932+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:07:51.932+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:07:51.985+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.314 seconds
[2024-11-20T11:08:23.437+0700] {processor.py:186} INFO - Started process (PID=149986) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:08:23.442+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:08:23.455+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.451+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:08:23.662+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:08:23.748+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.747+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:08:23.884+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.883+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:08:23.898+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.897+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:08:23.902+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.901+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:08:23.912+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:08:23.912+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:08:24.062+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.684 seconds
[2024-11-20T11:34:05.729+0700] {processor.py:186} INFO - Started process (PID=150412) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:05.732+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:34:05.740+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:05.739+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:05.874+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:05.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:05.953+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:34:06.025+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:06.024+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:34:06.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:06.035+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:34:06.040+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:06.039+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:34:06.043+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:06.043+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:34:06.112+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.402 seconds
[2024-11-20T11:34:39.295+0700] {processor.py:186} INFO - Started process (PID=150872) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:39.300+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:34:39.317+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.315+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:39.451+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:34:39.532+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.531+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:34:39.606+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.605+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:34:39.612+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.611+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:34:39.615+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.615+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:34:39.617+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:34:39.617+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:34:39.682+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.414 seconds
[2024-11-20T11:35:09.794+0700] {processor.py:186} INFO - Started process (PID=151317) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:09.796+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:35:09.800+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:09.799+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:09.913+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:09.971+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:09.971+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:35:10.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:10.035+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:35:10.040+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:10.039+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:35:10.042+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:10.042+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:35:10.045+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:10.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:35:10.097+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.324 seconds
[2024-11-20T11:35:40.202+0700] {processor.py:186} INFO - Started process (PID=151738) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:40.204+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:35:40.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.209+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:40.318+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:35:40.360+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.360+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:35:40.415+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.415+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:35:40.421+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.421+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:35:40.424+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.424+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:35:40.426+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:35:40.426+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:35:40.481+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.296 seconds
[2024-11-20T11:36:10.623+0700] {processor.py:186} INFO - Started process (PID=152072) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:10.628+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:36:10.637+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.636+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:10.744+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:10.787+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.786+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:36:10.843+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.843+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:36:10.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.849+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:36:10.853+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.852+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:36:10.858+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:10.858+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:36:10.907+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.305 seconds
[2024-11-20T11:36:41.306+0700] {processor.py:186} INFO - Started process (PID=152393) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:41.308+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:36:41.312+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.311+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:41.402+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:36:41.453+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.453+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:36:41.500+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.500+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:36:41.505+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.504+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:36:41.508+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.507+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:36:41.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:36:41.511+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:36:41.661+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.369 seconds
[2024-11-20T11:37:12.358+0700] {processor.py:186} INFO - Started process (PID=152695) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:12.361+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:37:12.365+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.365+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:12.466+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:12.504+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.504+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:37:12.551+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.551+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:37:12.556+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.555+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:37:12.558+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.557+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:37:12.561+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:12.560+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:37:12.595+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.261 seconds
[2024-11-20T11:37:43.130+0700] {processor.py:186} INFO - Started process (PID=152995) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:43.132+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:37:43.138+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.136+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:43.223+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:37:43.293+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.292+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:37:43.339+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.339+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:37:43.343+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.343+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:37:43.349+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.349+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:37:43.351+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:37:43.350+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:37:43.391+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.274 seconds
[2024-11-20T11:38:13.524+0700] {processor.py:186} INFO - Started process (PID=153335) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:13.532+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:38:13.537+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.535+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:13.612+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:13.660+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.659+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:38:13.694+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.694+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:38:13.697+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.697+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:38:13.699+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.698+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:38:13.702+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:13.702+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:38:13.732+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.233 seconds
[2024-11-20T11:38:45.029+0700] {processor.py:186} INFO - Started process (PID=154410) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:45.030+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:38:45.058+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.058+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:45.209+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:38:45.273+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.272+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:38:45.341+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.341+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:38:45.345+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.345+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:38:45.348+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.348+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:38:45.352+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:38:45.352+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:38:45.402+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.421 seconds
[2024-11-20T11:39:20.039+0700] {processor.py:186} INFO - Started process (PID=154751) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:20.043+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:39:20.049+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.048+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:20.228+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:20.334+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.333+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:39:20.448+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.447+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:39:20.458+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.457+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:39:20.462+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.461+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:39:20.465+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:20.464+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:39:20.588+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.573 seconds
[2024-11-20T11:39:59.235+0700] {processor.py:186} INFO - Started process (PID=155123) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:59.241+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:39:59.254+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.253+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:59.432+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:39:59.510+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.509+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:39:59.600+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.600+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:39:59.610+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.609+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:39:59.617+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.616+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:39:59.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:39:59.620+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:39:59.709+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.496 seconds
[2024-11-20T11:40:30.623+0700] {processor.py:186} INFO - Started process (PID=155675) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:40:30.626+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:40:30.639+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:30.637+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:40:30.901+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:40:31.138+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:31.138+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:40:31.345+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:31.344+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:40:31.354+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:31.353+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:40:31.357+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:31.356+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:40:31.363+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:40:31.362+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:40:31.477+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.875 seconds
[2024-11-20T11:41:02.178+0700] {processor.py:186} INFO - Started process (PID=156216) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:02.185+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:41:02.199+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.199+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:02.317+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:02.363+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.362+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:41:02.405+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.404+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:41:02.410+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.409+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:41:02.412+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.412+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:41:02.414+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:02.414+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:41:02.450+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.289 seconds
[2024-11-20T11:41:32.673+0700] {processor.py:186} INFO - Started process (PID=156579) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:32.676+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:41:32.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.682+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:32.800+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:41:32.854+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.853+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:41:32.913+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.912+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:41:32.924+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.918+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:41:32.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:41:32.932+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:41:32.931+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:41:33.002+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.348 seconds
[2024-11-20T11:42:05.412+0700] {processor.py:186} INFO - Started process (PID=156892) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:05.417+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:42:05.431+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:05.429+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:05.845+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:06.020+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:06.018+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:42:06.261+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:06.260+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:42:06.275+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:06.275+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:42:06.282+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:06.282+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:42:06.287+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:06.286+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:42:06.397+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.030 seconds
[2024-11-20T11:42:37.022+0700] {processor.py:186} INFO - Started process (PID=157198) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:37.026+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:42:37.037+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.035+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:37.258+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:42:37.382+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.381+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:42:37.542+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.541+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:42:37.580+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.573+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:42:37.592+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.591+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:42:37.603+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:42:37.602+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:42:37.729+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.735 seconds
[2024-11-20T11:43:08.016+0700] {processor.py:186} INFO - Started process (PID=157543) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:08.021+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:43:08.032+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.031+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:08.173+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:08.240+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.240+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:43:08.331+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.330+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:43:08.338+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.337+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:43:08.342+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.341+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:43:08.346+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:08.346+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:43:08.423+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.426 seconds
[2024-11-20T11:43:39.478+0700] {processor.py:186} INFO - Started process (PID=157897) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:39.479+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:43:39.482+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.481+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:39.530+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:43:39.554+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.554+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:43:39.580+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.580+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:43:39.583+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.583+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:43:39.585+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.584+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:43:39.586+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:43:39.586+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:43:39.611+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.142 seconds
[2024-11-20T11:44:10.479+0700] {processor.py:186} INFO - Started process (PID=158193) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:10.482+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:44:10.487+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.486+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:10.589+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:10.645+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.644+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:44:10.713+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.712+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:44:10.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.717+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:44:10.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.720+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:44:10.725+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:10.724+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:44:10.771+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.307 seconds
[2024-11-20T11:44:41.237+0700] {processor.py:186} INFO - Started process (PID=158495) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:41.240+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:44:41.248+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.247+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:41.546+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:44:41.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.771+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:44:41.911+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.910+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:44:41.922+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.922+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:44:41.927+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.926+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:44:41.935+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:44:41.934+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:44:42.049+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.850 seconds
[2024-11-20T11:45:16.120+0700] {processor.py:186} INFO - Started process (PID=159069) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:16.122+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:45:16.133+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.132+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:16.402+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:16.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.510+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:45:16.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.670+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:45:16.678+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.677+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:45:16.682+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.681+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:45:16.686+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:16.685+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:45:16.763+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.723 seconds
[2024-11-20T11:45:47.533+0700] {processor.py:186} INFO - Started process (PID=160259) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:47.536+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:45:47.544+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:47.544+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:47.936+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:45:48.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:48.046+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:45:48.151+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:48.150+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:45:48.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:48.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:45:48.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:48.161+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:45:48.167+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:45:48.167+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:45:48.234+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.714 seconds
[2024-11-20T11:46:19.098+0700] {processor.py:186} INFO - Started process (PID=160803) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:19.103+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:46:19.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.107+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:19.241+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:19.329+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.328+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:46:19.404+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.399+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:46:19.412+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.412+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:46:19.420+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.420+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:46:19.423+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:19.423+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:46:19.492+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.404 seconds
[2024-11-20T11:46:51.063+0700] {processor.py:186} INFO - Started process (PID=161264) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:51.083+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:46:51.122+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:51.121+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:51.537+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:46:51.894+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:51.889+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:46:52.121+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:52.120+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:46:52.132+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:52.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:46:52.138+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:52.137+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:46:52.143+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:46:52.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:46:52.342+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.389 seconds
[2024-11-20T11:47:51.065+0700] {processor.py:186} INFO - Started process (PID=161698) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:47:51.070+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:47:51.108+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.103+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:47:51.458+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:47:51.595+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.594+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:47:51.881+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.880+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:47:51.907+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.904+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:47:51.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.916+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:47:51.922+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:47:51.921+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:47:52.101+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.098 seconds
[2024-11-20T11:48:22.532+0700] {processor.py:186} INFO - Started process (PID=162248) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:48:22.535+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:48:22.552+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.551+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:48:22.700+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:48:22.799+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.799+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:48:22.895+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.894+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:48:22.908+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.908+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:48:22.914+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.913+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:48:22.920+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:48:22.919+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:48:23.012+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.510 seconds
[2024-11-20T11:49:22.979+0700] {processor.py:186} INFO - Started process (PID=162733) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:22.986+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:49:23.003+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:23.000+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:23.345+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:23.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:23.668+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:49:24.573+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:24.556+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:49:24.679+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:24.678+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:49:24.769+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:24.759+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:49:24.802+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:24.791+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:49:25.426+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.551 seconds
[2024-11-20T11:49:56.938+0700] {processor.py:186} INFO - Started process (PID=163046) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:56.940+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:49:56.945+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:56.944+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:57.077+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:49:57.134+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:57.133+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:49:57.196+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:57.195+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:49:57.201+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:57.200+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:49:57.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:57.203+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:49:57.207+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:49:57.206+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:49:57.299+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.377 seconds
[2024-11-20T11:50:28.252+0700] {processor.py:186} INFO - Started process (PID=163354) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:28.253+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:50:28.257+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.257+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:28.339+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:28.382+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.381+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:50:28.425+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.424+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:50:28.430+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.429+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:50:28.432+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.432+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:50:28.434+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:28.434+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:50:28.480+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.244 seconds
[2024-11-20T11:50:58.849+0700] {processor.py:186} INFO - Started process (PID=163643) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:58.859+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:50:58.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:58.863+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:59.063+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:50:59.190+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:59.190+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:50:59.251+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:59.250+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:50:59.255+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:59.254+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:50:59.256+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:59.256+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:50:59.258+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:50:59.257+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:50:59.307+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.485 seconds
[2024-11-20T11:51:29.919+0700] {processor.py:186} INFO - Started process (PID=163991) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:51:29.921+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:51:29.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:29.926+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:51:30.065+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:51:30.129+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:30.128+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:51:30.191+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:30.191+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:51:30.208+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:30.208+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:51:30.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:30.214+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:51:30.217+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:51:30.217+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:51:30.288+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.383 seconds
[2024-11-20T11:52:03.576+0700] {processor.py:186} INFO - Started process (PID=164387) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:03.582+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:52:03.605+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:03.600+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:03.853+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:04.069+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:04.068+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:52:04.171+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:04.170+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:52:04.178+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:04.177+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:52:04.182+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:04.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:52:04.191+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:04.190+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:52:04.296+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.767 seconds
[2024-11-20T11:52:35.483+0700] {processor.py:186} INFO - Started process (PID=164722) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:35.488+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:52:35.495+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.494+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:35.663+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:52:35.743+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.743+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:52:35.813+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.812+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:52:35.820+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.820+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:52:35.824+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.824+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:52:35.828+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:52:35.827+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:52:35.896+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.435 seconds
[2024-11-20T11:53:06.090+0700] {processor.py:186} INFO - Started process (PID=165091) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:06.092+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:53:06.098+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.097+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:06.207+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:06.249+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.249+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:53:06.304+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.304+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:53:06.308+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.308+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:53:06.313+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.313+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:53:06.317+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:06.317+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:53:06.375+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.304 seconds
[2024-11-20T11:53:36.791+0700] {processor.py:186} INFO - Started process (PID=165411) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:36.792+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:53:36.795+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.795+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:36.857+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:53:36.883+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.883+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:53:36.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.921+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:53:36.924+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.924+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:53:36.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.926+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:53:36.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:53:36.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:53:36.980+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.199 seconds
[2024-11-20T11:54:10.888+0700] {processor.py:186} INFO - Started process (PID=166005) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:10.898+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:54:10.933+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:10.921+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:11.439+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:11.661+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:11.658+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:54:11.894+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:11.893+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:54:11.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:11.916+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:54:11.927+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:11.924+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:54:11.935+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:11.934+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:54:12.228+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.484 seconds
[2024-11-20T11:54:50.123+0700] {processor.py:186} INFO - Started process (PID=166385) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:50.130+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:54:50.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.152+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:50.469+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:54:50.651+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.649+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:54:50.933+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.932+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:54:50.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.952+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:54:50.957+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.957+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:54:50.975+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:54:50.974+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:54:51.281+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.196 seconds
[2024-11-20T11:55:21.738+0700] {processor.py:186} INFO - Started process (PID=166708) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:21.742+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:55:21.746+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.746+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:21.834+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:21.872+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.872+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:55:21.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.919+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:55:21.925+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:55:21.927+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:55:21.929+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:21.929+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:55:21.971+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.244 seconds
[2024-11-20T11:55:52.285+0700] {processor.py:186} INFO - Started process (PID=167050) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:52.287+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:55:52.296+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.294+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:52.497+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:55:52.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.682+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:55:52.859+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.858+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:55:52.865+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.865+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:55:52.871+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.871+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:55:52.876+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:55:52.874+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:55:53.075+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.826 seconds
[2024-11-20T11:56:23.128+0700] {processor.py:186} INFO - Started process (PID=167362) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:23.130+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:56:23.134+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.133+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:23.203+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:23.235+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.234+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:56:23.272+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.272+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:56:23.276+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.276+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:56:23.278+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.277+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:56:23.280+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:23.279+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:56:23.316+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.200 seconds
[2024-11-20T11:56:53.473+0700] {processor.py:186} INFO - Started process (PID=167657) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:53.474+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:56:53.477+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.476+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:53.532+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:56:53.561+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.560+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:56:53.592+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.592+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:56:53.596+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.595+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:56:53.597+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.597+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:56:53.599+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:56:53.598+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:56:53.627+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.162 seconds
[2024-11-20T11:57:23.893+0700] {processor.py:186} INFO - Started process (PID=167947) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:23.899+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:57:23.903+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:23.902+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:23.957+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:23.984+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:23.983+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:57:24.022+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:24.021+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:57:24.025+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:24.025+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:57:24.027+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:24.027+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:57:24.029+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:24.029+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:57:24.252+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.366 seconds
[2024-11-20T11:57:54.380+0700] {processor.py:186} INFO - Started process (PID=168239) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:54.382+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:57:54.388+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.387+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:54.490+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:57:54.542+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.542+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:57:54.601+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.601+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:57:54.610+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.610+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:57:54.617+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.616+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:57:54.620+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:57:54.619+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:57:54.698+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.334 seconds
[2024-11-20T11:58:25.145+0700] {processor.py:186} INFO - Started process (PID=168573) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:25.150+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:58:25.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.160+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:25.406+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:25.473+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.472+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:58:25.589+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.589+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:58:25.599+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.598+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:58:25.604+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.603+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:58:25.607+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:25.606+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:58:25.677+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.557 seconds
[2024-11-20T11:58:55.984+0700] {processor.py:186} INFO - Started process (PID=168868) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:55.986+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:58:55.990+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:55.990+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:56.088+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:58:56.137+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:56.136+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:58:56.203+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:56.203+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:58:56.209+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:56.208+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:58:56.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:56.211+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:58:56.213+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:58:56.213+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:58:56.258+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.285 seconds
[2024-11-20T11:59:27.598+0700] {processor.py:186} INFO - Started process (PID=169169) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:27.603+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:59:27.620+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:27.611+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:27.842+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:27.933+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:27.932+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:59:28.023+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:28.022+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:59:28.031+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:28.030+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:59:28.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:28.034+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:59:28.038+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:28.038+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:59:28.106+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.533 seconds
[2024-11-20T11:59:58.570+0700] {processor.py:186} INFO - Started process (PID=169461) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:58.573+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T11:59:58.577+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:58.576+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:58.674+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T11:59:58.715+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:58.715+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T11:59:59.018+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:59.018+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T11:59:59.026+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:59.025+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T11:59:59.034+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:59.033+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T11:59:59.037+0700] {logging_mixin.py:190} INFO - [2024-11-20T11:59:59.037+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T11:59:59.102+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.543 seconds
[2024-11-20T12:00:29.717+0700] {processor.py:186} INFO - Started process (PID=170507) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:00:29.725+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:00:29.730+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:29.729+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:00:29.897+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:00:29.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:29.962+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:00:30.390+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:30.389+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:00:30.398+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:30.398+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:00:30.403+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:30.402+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:00:30.407+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:00:30.407+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:00:30.477+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.787 seconds
[2024-11-20T12:01:00.937+0700] {processor.py:186} INFO - Started process (PID=170817) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:00.942+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:01:00.952+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:00.951+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:01.437+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:01.942+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:01.930+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:01:02.078+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:02.077+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:01:02.093+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:02.091+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:01:02.098+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:02.097+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:01:02.102+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:02.102+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:01:03.031+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.133 seconds
[2024-11-20T12:01:42.837+0700] {processor.py:186} INFO - Started process (PID=171254) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:42.841+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:01:42.853+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:42.851+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:43.721+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:01:43.797+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:43.796+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:01:43.876+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:43.876+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:01:43.887+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:43.885+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:01:43.893+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:43.892+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:01:43.897+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:01:43.896+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:01:43.987+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.176 seconds
[2024-11-20T12:02:14.761+0700] {processor.py:186} INFO - Started process (PID=171631) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:14.762+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:02:14.765+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.764+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:14.817+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:14.843+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.843+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:02:14.870+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.870+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:02:14.874+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.874+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:02:14.876+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.875+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:02:14.877+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:14.877+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:02:14.905+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.154 seconds
[2024-11-20T12:02:45.646+0700] {processor.py:186} INFO - Started process (PID=171928) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:45.651+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:02:45.666+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:45.664+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:46.030+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:02:46.193+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:46.192+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:02:46.325+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:46.324+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:02:46.337+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:46.336+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:02:46.343+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:46.342+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:02:46.347+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:02:46.347+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:02:46.432+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.820 seconds
[2024-11-20T12:03:17.109+0700] {processor.py:186} INFO - Started process (PID=172264) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:17.114+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:03:17.121+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.120+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:17.222+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:17.268+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.268+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:03:17.331+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.330+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:03:17.337+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.336+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:03:17.341+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.341+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:03:17.345+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.345+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:03:17.445+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.350 seconds
[2024-11-20T12:03:47.742+0700] {processor.py:186} INFO - Started process (PID=172637) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:47.751+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:03:47.762+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:47.760+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:47.976+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:03:48.095+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:48.092+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:03:48.271+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:48.270+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:03:48.333+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:48.333+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:03:48.353+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:48.352+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:03:48.377+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:03:48.372+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:03:48.636+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.916 seconds
[2024-11-20T12:04:18.774+0700] {processor.py:186} INFO - Started process (PID=172977) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:04:18.777+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:04:18.781+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.780+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:04:18.848+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:04:18.880+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.880+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:04:18.920+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.919+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:04:18.923+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.923+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:04:18.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:04:18.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:04:18.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:04:18.972+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.210 seconds
[2024-11-20T12:05:04.914+0700] {processor.py:186} INFO - Started process (PID=173325) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:04.938+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:05:04.972+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:04.965+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:05.890+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:06.193+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:06.166+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:05:06.581+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:06.580+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:05:06.607+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:06.606+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:05:06.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:06.617+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:05:06.626+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:06.625+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:05:06.974+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.295 seconds
[2024-11-20T12:05:37.735+0700] {processor.py:186} INFO - Started process (PID=173693) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:39.277+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:05:39.284+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.283+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:39.352+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:05:39.389+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.389+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:05:39.454+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.453+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:05:39.462+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.462+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:05:39.466+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.465+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:05:39.469+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:05:39.468+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:05:41.727+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 4.020 seconds
[2024-11-20T12:06:12.572+0700] {processor.py:186} INFO - Started process (PID=174057) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:12.580+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:06:12.599+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:12.597+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:12.879+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:13.060+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:13.059+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:06:13.296+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:13.294+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:06:13.326+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:13.325+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:06:13.337+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:13.336+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:06:13.349+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:13.348+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:06:13.625+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.117 seconds
[2024-11-20T12:06:43.789+0700] {processor.py:186} INFO - Started process (PID=174752) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:43.791+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:06:43.796+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:43.795+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:43.893+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:06:43.953+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:43.952+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:06:44.028+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:44.027+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:06:44.048+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:44.048+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:06:44.051+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:44.050+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:06:44.053+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:06:44.053+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:06:44.140+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.363 seconds
[2024-11-20T12:07:14.463+0700] {processor.py:186} INFO - Started process (PID=175049) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:14.464+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:07:14.470+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.470+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:14.587+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:14.630+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.629+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:07:14.674+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.674+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:07:14.678+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.678+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:07:14.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.680+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:07:14.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:14.682+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:07:14.719+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.266 seconds
[2024-11-20T12:07:51.419+0700] {processor.py:186} INFO - Started process (PID=175368) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:51.436+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:07:51.484+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:51.462+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:51.697+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:07:51.782+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:51.781+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:07:51.974+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:51.969+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:07:51.989+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:51.986+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:07:51.995+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:51.994+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:07:52.006+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:07:52.005+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:07:52.124+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.754 seconds
[2024-11-20T12:08:23.894+0700] {processor.py:186} INFO - Started process (PID=175708) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:23.897+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:08:23.908+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:23.907+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:24.068+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:24.150+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:24.149+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:08:24.242+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:24.241+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:08:24.250+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:24.249+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:08:24.255+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:24.254+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:08:24.259+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:24.258+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:08:24.334+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.465 seconds
[2024-11-20T12:08:54.985+0700] {processor.py:186} INFO - Started process (PID=176214) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:54.986+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:08:54.989+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:54.989+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:55.053+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:08:55.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:55.076+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:08:55.103+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:55.102+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:08:55.106+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:55.105+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:08:55.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:55.107+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:08:55.109+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:08:55.108+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:08:55.135+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.157 seconds
[2024-11-20T12:09:45.529+0700] {processor.py:186} INFO - Started process (PID=176921) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:09:45.535+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:09:45.574+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:45.571+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:09:45.973+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:09:46.134+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:46.133+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:09:46.330+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:46.330+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:09:46.345+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:46.344+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:09:46.361+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:46.360+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:09:46.368+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:09:46.366+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:09:46.584+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.153 seconds
[2024-11-20T12:10:37.398+0700] {processor.py:186} INFO - Started process (PID=178790) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:10:37.405+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:10:37.429+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:37.427+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:10:38.424+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:10:42.656+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:42.582+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:10:43.644+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:43.588+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:10:43.881+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:43.880+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:10:44.082+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:43.978+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:10:44.256+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:10:44.255+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:10:48.426+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 11.057 seconds
[2024-11-20T12:12:05.066+0700] {processor.py:186} INFO - Started process (PID=180927) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:05.072+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:12:05.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.078+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:05.220+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:05.288+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.287+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:12:05.354+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.352+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:12:05.367+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.367+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:12:05.372+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.371+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:12:05.374+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:05.374+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:12:05.437+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.396 seconds
[2024-11-20T12:12:38.613+0700] {processor.py:186} INFO - Started process (PID=181244) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:38.645+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:12:38.703+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:38.683+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:39.203+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:12:39.594+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:39.594+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:12:40.778+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:40.777+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:12:40.827+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:40.821+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:12:40.847+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:40.844+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:12:40.854+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:12:40.853+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:12:41.983+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 3.486 seconds
[2024-11-20T12:13:12.414+0700] {processor.py:186} INFO - Started process (PID=181632) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:12.431+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:13:12.439+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.438+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:12.577+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:12.644+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.643+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:13:12.705+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.705+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:13:12.713+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.712+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:13:12.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.717+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:13:12.723+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:12.722+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:13:12.788+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.413 seconds
[2024-11-20T12:13:43.462+0700] {processor.py:186} INFO - Started process (PID=181974) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:43.467+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:13:43.475+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.474+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:43.683+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:13:43.791+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.791+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:13:43.918+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.918+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:13:43.943+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.939+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:13:43.951+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.950+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:13:43.957+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:13:43.957+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:13:44.103+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.670 seconds
[2024-11-20T12:14:26.875+0700] {processor.py:186} INFO - Started process (PID=182396) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:14:26.882+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:14:26.910+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:26.908+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:14:27.319+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:14:27.495+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:27.494+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:14:28.274+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:28.273+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:14:28.320+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:28.313+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:14:28.332+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:28.331+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:14:28.356+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:14:28.355+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:14:28.754+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.980 seconds
[2024-11-20T12:30:13.774+0700] {processor.py:186} INFO - Started process (PID=6619) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:13.776+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:30:13.783+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.783+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:13.864+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:13.913+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.913+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:30:13.955+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.955+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:30:13.960+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.959+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:30:13.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.962+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:30:13.965+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:13.965+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:30:14.002+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.235 seconds
[2024-11-20T12:30:51.815+0700] {processor.py:186} INFO - Started process (PID=7113) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:51.826+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:30:51.838+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:51.837+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:52.031+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:30:52.127+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:52.126+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:30:52.210+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:52.209+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:30:52.219+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:52.218+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:30:52.224+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:52.223+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:30:52.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:30:52.228+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:30:52.337+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.570 seconds
[2024-11-20T12:31:22.638+0700] {processor.py:186} INFO - Started process (PID=8141) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:22.648+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:31:22.661+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:22.660+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:22.872+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:23.000+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:22.997+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:31:23.113+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:23.107+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:31:23.126+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:23.125+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:31:23.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:23.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:31:23.137+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:23.136+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:31:23.307+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.680 seconds
[2024-11-20T12:31:54.065+0700] {processor.py:186} INFO - Started process (PID=8658) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:54.067+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:31:54.069+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.069+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:54.172+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:31:54.221+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.221+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:31:54.290+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.289+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:31:54.295+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.295+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:31:54.298+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.298+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:31:54.301+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:31:54.301+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:31:54.354+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.304 seconds
[2024-11-20T12:32:24.887+0700] {processor.py:186} INFO - Started process (PID=8800) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:24.889+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:32:24.897+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:24.896+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:25.054+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:25.133+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:25.133+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:32:25.214+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:25.213+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:32:25.225+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:25.225+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:32:25.228+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:25.227+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:32:25.231+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:25.230+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:32:25.290+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.414 seconds
[2024-11-20T12:32:55.426+0700] {processor.py:186} INFO - Started process (PID=8931) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:55.429+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:32:55.432+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.432+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:55.524+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:32:55.605+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.604+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:32:55.668+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.668+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:32:55.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.680+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:32:55.685+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.684+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:32:55.690+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:32:55.689+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:32:55.767+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.357 seconds
[2024-11-20T12:33:25.848+0700] {processor.py:186} INFO - Started process (PID=9067) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:25.849+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:33:25.852+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.851+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:25.920+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:25.950+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.950+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:33:25.976+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.976+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:33:25.980+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.980+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:33:25.982+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.982+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:33:25.984+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.984+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:33:26.018+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.177 seconds
[2024-11-20T12:33:56.221+0700] {processor.py:186} INFO - Started process (PID=9197) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:56.223+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:33:56.226+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.225+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:56.261+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:33:56.280+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.280+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:33:56.299+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.299+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:33:56.301+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.301+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:33:56.303+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.302+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:33:56.304+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.303+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:33:56.322+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.107 seconds
[2024-11-20T12:34:27.147+0700] {processor.py:186} INFO - Started process (PID=9418) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:27.148+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:34:27.150+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.150+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:27.186+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:27.205+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.205+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:34:27.225+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.224+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:34:27.227+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.227+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:34:27.228+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.228+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:34:27.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.229+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:34:27.249+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.110 seconds
[2024-11-20T12:34:57.373+0700] {processor.py:186} INFO - Started process (PID=9569) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:57.375+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:34:57.379+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.378+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:57.430+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:34:57.449+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.449+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:34:57.467+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.467+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:34:57.470+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.469+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:34:57.471+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.470+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:34:57.472+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:34:57.472+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:34:57.490+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.127 seconds
[2024-11-20T12:35:27.950+0700] {processor.py:186} INFO - Started process (PID=9767) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:27.951+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:35:27.954+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:27.954+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:27.990+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:28.023+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:28.023+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:35:28.041+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:28.041+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:35:28.043+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:28.043+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:35:28.044+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:28.044+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:35:28.045+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:28.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:35:28.062+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.121 seconds
[2024-11-20T12:35:58.759+0700] {processor.py:186} INFO - Started process (PID=9997) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:58.761+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:35:58.764+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.763+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:58.804+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:35:58.822+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.822+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:35:58.841+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.841+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:35:58.843+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.843+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:35:58.844+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.844+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:35:58.846+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:35:58.845+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:35:58.871+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.124 seconds
[2024-11-20T12:36:29.097+0700] {processor.py:186} INFO - Started process (PID=10255) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:29.098+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:36:29.104+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.104+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:29.144+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:29.183+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.183+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:36:29.203+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.202+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:36:29.208+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.208+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:36:29.210+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.210+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:36:29.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:29.211+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:36:29.231+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.139 seconds
[2024-11-20T12:36:59.453+0700] {processor.py:186} INFO - Started process (PID=10389) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:59.454+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:36:59.459+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.459+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:59.530+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:36:59.568+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.567+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:36:59.810+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.809+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:36:59.814+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.814+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:36:59.817+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.816+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:36:59.819+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:36:59.819+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:36:59.855+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.413 seconds
[2024-11-20T12:37:29.934+0700] {processor.py:186} INFO - Started process (PID=10522) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:37:29.936+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:37:29.939+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:29.938+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:37:30.015+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:37:30.053+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:30.053+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:37:30.298+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:30.298+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:37:30.304+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:30.303+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:37:30.306+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:30.306+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:37:30.309+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:37:30.308+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:37:30.351+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.425 seconds
[2024-11-20T12:38:00.693+0700] {processor.py:186} INFO - Started process (PID=10671) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:00.695+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:38:00.701+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:00.700+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:00.781+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:00.820+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:00.820+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:38:00.877+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:00.876+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:38:01.171+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:01.170+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:38:01.174+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:01.173+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:38:01.177+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:01.177+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:38:01.246+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.561 seconds
[2024-11-20T12:38:31.636+0700] {processor.py:186} INFO - Started process (PID=10805) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:31.637+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:38:31.639+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.639+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:31.694+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:38:31.730+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.729+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:38:31.763+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.763+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:38:31.767+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.766+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:38:31.770+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.770+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:38:31.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.772+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:38:31.808+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.179 seconds
[2024-11-20T12:39:02.952+0700] {processor.py:186} INFO - Started process (PID=11089) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:02.955+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:39:02.958+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:02.958+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:03.067+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:03.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:03.106+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:39:03.147+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:03.146+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:39:03.151+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:03.151+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:39:03.154+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:03.153+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:39:03.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:03.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:39:03.203+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.280 seconds
[2024-11-20T12:39:33.694+0700] {processor.py:186} INFO - Started process (PID=11731) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:33.695+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:39:33.697+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.696+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:33.743+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:39:33.777+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.777+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:39:33.803+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.803+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:39:33.806+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.805+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:39:33.807+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.807+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:39:33.808+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:39:33.808+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:39:33.838+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.150 seconds
[2024-11-20T12:40:05.168+0700] {processor.py:186} INFO - Started process (PID=12414) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:05.173+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:40:05.183+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.179+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:05.333+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:05.403+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.402+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:40:05.469+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.468+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:40:05.475+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.474+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:40:05.478+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.477+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:40:05.481+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:05.480+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:40:05.545+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.397 seconds
[2024-11-20T12:40:35.619+0700] {processor.py:186} INFO - Started process (PID=12625) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:35.621+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:40:35.624+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.624+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:35.704+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:40:35.745+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.744+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:40:35.804+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.802+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:40:35.818+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.818+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:40:35.821+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.820+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:40:35.823+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:40:35.823+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:40:35.901+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.291 seconds
[2024-11-20T12:41:06.788+0700] {processor.py:186} INFO - Started process (PID=12759) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:06.789+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:41:06.794+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.793+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:06.886+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:06.914+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.913+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:41:06.941+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.941+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:41:06.944+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.944+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:41:06.946+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:41:06.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:06.947+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:41:06.998+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.219 seconds
[2024-11-20T12:41:37.076+0700] {processor.py:186} INFO - Started process (PID=13032) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:37.077+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:41:37.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.078+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:37.118+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:41:37.137+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.137+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:41:37.158+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.158+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:41:37.161+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.161+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:41:37.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.162+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:41:37.163+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:41:37.163+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:41:37.182+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.111 seconds
[2024-11-20T12:42:07.360+0700] {processor.py:186} INFO - Started process (PID=13237) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:07.361+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:42:07.365+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.364+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:07.477+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:07.550+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.548+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:42:07.634+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.634+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:42:07.641+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.640+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:42:07.644+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.643+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:42:07.646+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:07.646+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:42:07.714+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.367 seconds
[2024-11-20T12:42:38.062+0700] {processor.py:186} INFO - Started process (PID=13550) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:38.067+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:42:38.084+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.080+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:38.203+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:42:38.276+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.275+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:42:38.343+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.342+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:42:38.354+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.353+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:42:38.363+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.363+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:42:38.368+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:42:38.368+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:42:38.478+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.438 seconds
[2024-11-20T12:43:09.248+0700] {processor.py:186} INFO - Started process (PID=14491) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:09.254+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:43:09.281+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:09.280+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:09.791+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:10.115+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:10.115+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:43:10.474+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:10.473+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:43:10.515+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:10.515+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:43:10.535+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:10.535+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:43:10.555+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:10.555+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:43:10.860+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.659 seconds
[2024-11-20T12:43:41.260+0700] {processor.py:186} INFO - Started process (PID=14728) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:41.267+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:43:41.271+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.270+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:41.427+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:43:41.486+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.486+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:43:41.610+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.610+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:43:41.617+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.616+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:43:41.620+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.619+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:43:41.624+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:43:41.623+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:43:41.680+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.433 seconds
[2024-11-20T12:44:12.165+0700] {processor.py:186} INFO - Started process (PID=15109) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:12.166+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:44:12.176+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.176+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:12.237+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:12.274+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.274+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:44:12.305+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.305+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:44:12.308+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.308+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:44:12.309+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.309+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:44:12.311+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:12.310+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:44:12.336+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.187 seconds
[2024-11-20T12:44:43.529+0700] {processor.py:186} INFO - Started process (PID=15751) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:43.532+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:44:43.538+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.537+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:43.706+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:44:43.776+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.776+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:44:43.861+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.860+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:44:43.871+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.871+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:44:43.876+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.876+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:44:43.885+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:44:43.884+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:44:43.940+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.430 seconds
[2024-11-20T12:45:15.768+0700] {processor.py:186} INFO - Started process (PID=15918) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:15.777+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:45:15.788+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:15.787+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:15.967+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:16.050+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:16.049+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:45:16.148+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:16.148+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:45:16.165+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:16.164+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:45:16.174+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:16.174+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:45:16.187+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:16.184+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:45:16.323+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.583 seconds
[2024-11-20T12:45:46.420+0700] {processor.py:186} INFO - Started process (PID=16076) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:46.422+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:45:46.425+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.424+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:46.522+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:45:46.576+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.576+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:45:46.632+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.632+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:45:46.638+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.637+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:45:46.641+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.640+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:45:46.643+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:45:46.643+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:45:46.693+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.283 seconds
[2024-11-20T12:46:17.652+0700] {processor.py:186} INFO - Started process (PID=16377) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:17.654+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:46:17.677+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:17.674+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:17.910+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:18.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:18.035+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:46:18.117+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:18.116+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:46:18.125+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:18.124+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:46:18.139+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:18.139+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:46:18.143+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:18.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:46:18.228+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.604 seconds
[2024-11-20T12:46:48.442+0700] {processor.py:186} INFO - Started process (PID=16541) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:48.445+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:46:48.452+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.452+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:48.549+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:46:48.616+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.615+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:46:48.694+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.693+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:46:48.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.718+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:46:48.722+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.721+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:46:48.726+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:46:48.725+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:46:48.791+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.362 seconds
[2024-11-20T12:47:19.077+0700] {processor.py:186} INFO - Started process (PID=16710) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:19.079+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:47:19.083+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.082+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:19.170+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:19.215+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.214+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:47:19.276+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.276+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:47:19.283+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.282+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:47:19.286+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.285+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:47:19.288+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:19.288+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:47:19.347+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.282 seconds
[2024-11-20T12:47:49.448+0700] {processor.py:186} INFO - Started process (PID=16840) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:49.456+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:47:49.465+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.464+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:49.607+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:47:49.676+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.676+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:47:49.742+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.742+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:47:49.748+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.747+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:47:49.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.750+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:47:49.753+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:47:49.753+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:47:49.800+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.393 seconds
[2024-11-20T12:48:20.203+0700] {processor.py:186} INFO - Started process (PID=17140) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:20.212+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:48:20.220+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.219+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:20.439+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:20.584+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.580+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:48:20.684+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.684+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:48:20.697+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.696+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:48:20.702+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.702+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:48:20.708+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:20.708+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:48:20.837+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.687 seconds
[2024-11-20T12:48:51.062+0700] {processor.py:186} INFO - Started process (PID=17265) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:51.068+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:48:51.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.073+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:51.265+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:48:51.326+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.325+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:48:51.393+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.392+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:48:51.400+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.399+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:48:51.404+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:48:51.407+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:48:51.407+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:48:51.486+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.443 seconds
[2024-11-20T12:49:22.453+0700] {processor.py:186} INFO - Started process (PID=17435) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:22.457+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:49:22.461+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.460+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:22.573+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:22.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.620+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:49:22.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.683+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:49:22.694+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.694+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:49:22.701+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.700+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:49:22.708+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:22.707+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:49:22.781+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.340 seconds
[2024-11-20T12:49:53.511+0700] {processor.py:186} INFO - Started process (PID=17624) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:53.514+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:49:53.519+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.518+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:53.613+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:49:53.658+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.657+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:49:53.746+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.746+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:49:53.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.751+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:49:53.754+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.753+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:49:53.756+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:49:53.756+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:49:53.892+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.406 seconds
[2024-11-20T12:50:24.054+0700] {processor.py:186} INFO - Started process (PID=17882) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:24.059+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:50:24.068+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.067+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:24.196+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:24.262+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.262+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:50:24.333+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.333+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:50:24.341+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.340+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:50:24.346+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.345+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:50:24.349+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:24.348+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:50:24.405+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.378 seconds
[2024-11-20T12:50:54.686+0700] {processor.py:186} INFO - Started process (PID=18030) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:54.694+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:50:54.700+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.699+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:54.840+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:50:54.909+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.907+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:50:54.977+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.977+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:50:54.986+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.985+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:50:54.988+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.988+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:50:54.992+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:50:54.991+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:50:55.057+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.385 seconds
[2024-11-20T12:51:46.823+0700] {processor.py:186} INFO - Started process (PID=18522) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:51:46.832+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:51:46.842+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:46.842+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:51:47.031+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:51:47.081+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:47.080+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:51:47.140+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:47.138+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:51:47.156+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:47.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:51:47.166+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:47.166+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:51:47.174+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:51:47.174+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:51:47.328+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.585 seconds
[2024-11-20T12:52:17.667+0700] {processor.py:186} INFO - Started process (PID=18756) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:17.671+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:52:17.674+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.673+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:17.755+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:17.805+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.805+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:52:17.852+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.852+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:52:17.858+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.858+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:52:17.861+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.860+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:52:17.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:17.864+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:52:17.912+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.265 seconds
[2024-11-20T12:52:48.416+0700] {processor.py:186} INFO - Started process (PID=18895) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:48.420+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:52:48.425+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.424+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:48.578+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:52:48.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.677+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:52:48.818+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.818+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:52:48.832+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.832+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:52:48.842+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.842+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:52:48.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:52:48.850+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:52:48.956+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.553 seconds
[2024-11-20T12:53:19.562+0700] {processor.py:186} INFO - Started process (PID=19103) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:19.566+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:53:19.573+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:19.572+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:19.809+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:19.956+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:19.956+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:53:20.073+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:20.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:53:20.095+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:20.094+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:53:20.115+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:20.115+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:53:20.127+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:20.126+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:53:20.300+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.779 seconds
[2024-11-20T12:53:50.920+0700] {processor.py:186} INFO - Started process (PID=19261) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:50.922+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:53:50.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:50.925+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:51.006+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:53:51.042+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:51.041+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:53:51.096+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:51.096+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:53:51.109+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:51.108+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:53:51.110+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:51.110+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:53:51.113+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:53:51.113+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:53:51.153+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.244 seconds
[2024-11-20T12:54:21.793+0700] {processor.py:186} INFO - Started process (PID=19404) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:21.796+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:54:21.800+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:21.799+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:21.952+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:22.012+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:22.012+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:54:22.092+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:22.091+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:54:22.098+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:22.098+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:54:22.113+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:22.112+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:54:22.118+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:22.117+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:54:22.180+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.399 seconds
[2024-11-20T12:54:52.352+0700] {processor.py:186} INFO - Started process (PID=19559) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:52.354+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:54:52.367+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.366+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:52.567+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:54:52.658+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.657+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:54:52.732+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.731+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:54:52.738+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.738+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:54:52.744+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.744+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:54:52.748+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:54:52.748+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:54:52.834+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.519 seconds
[2024-11-20T12:55:23.106+0700] {processor.py:186} INFO - Started process (PID=19738) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:23.114+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:55:23.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.130+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:23.312+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:23.420+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.420+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:55:23.550+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.550+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:55:23.565+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.565+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:55:23.568+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.568+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:55:23.571+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:23.570+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:55:23.692+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.631 seconds
[2024-11-20T12:55:53.831+0700] {processor.py:186} INFO - Started process (PID=19948) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:53.833+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:55:53.839+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:53.839+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:53.967+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:55:54.012+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:54.011+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:55:54.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:54.079+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:55:54.085+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:54.085+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:55:54.089+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:54.089+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:55:54.091+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:55:54.091+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:55:54.146+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.330 seconds
[2024-11-20T12:56:24.466+0700] {processor.py:186} INFO - Started process (PID=20151) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:56:24.472+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:56:24.479+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:24.478+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:56:24.803+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:56:24.996+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:24.995+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:56:25.157+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:25.156+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:56:25.179+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:25.178+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:56:25.192+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:25.191+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:56:25.225+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:56:25.223+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:56:25.478+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.037 seconds
[2024-11-20T12:57:00.587+0700] {processor.py:186} INFO - Started process (PID=20313) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:00.593+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:57:00.603+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:00.601+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:00.872+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:00.939+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:00.939+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:57:01.006+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:01.005+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:57:01.016+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:01.015+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:57:01.022+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:01.021+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:57:01.030+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:01.027+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:57:01.130+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.571 seconds
[2024-11-20T12:57:31.362+0700] {processor.py:186} INFO - Started process (PID=20449) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:31.366+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:57:31.377+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.376+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:31.502+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:57:31.553+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.553+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:57:31.625+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.625+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:57:31.630+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.630+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:57:31.642+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.642+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:57:31.645+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:57:31.644+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:57:31.683+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.331 seconds
[2024-11-20T12:58:02.254+0700] {processor.py:186} INFO - Started process (PID=20577) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:02.260+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:58:02.269+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.267+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:02.447+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:02.568+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.567+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:58:02.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.669+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:58:02.680+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.680+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:58:02.685+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.684+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:58:02.696+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:02.695+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:58:02.845+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.622 seconds
[2024-11-20T12:58:33.108+0700] {processor.py:186} INFO - Started process (PID=20711) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:33.109+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:58:33.112+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.112+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:33.173+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:58:33.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.204+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:58:33.238+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.237+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:58:33.241+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.241+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:58:33.243+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.243+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:58:33.245+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:58:33.245+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:58:33.283+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.182 seconds
[2024-11-20T12:59:03.869+0700] {processor.py:186} INFO - Started process (PID=20850) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:03.873+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:59:03.876+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:03.875+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:03.975+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:04.051+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:04.050+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:59:04.148+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:04.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:59:04.155+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:04.155+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:59:04.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:04.161+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:59:04.165+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:04.165+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:59:04.218+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.360 seconds
[2024-11-20T12:59:35.039+0700] {processor.py:186} INFO - Started process (PID=20982) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:35.045+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T12:59:35.071+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.070+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:35.310+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T12:59:35.419+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.418+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T12:59:35.557+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.556+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T12:59:35.570+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.569+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T12:59:35.576+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.575+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T12:59:35.583+0700] {logging_mixin.py:190} INFO - [2024-11-20T12:59:35.582+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T12:59:35.710+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.738 seconds
[2024-11-20T13:00:12.027+0700] {processor.py:186} INFO - Started process (PID=21196) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:12.043+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:00:12.081+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:12.079+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:12.583+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:12.949+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:12.931+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:00:13.385+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:13.378+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:00:13.424+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:13.420+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:00:13.435+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:13.434+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:00:13.452+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:13.447+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:00:13.630+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.789 seconds
[2024-11-20T13:00:58.160+0700] {processor.py:186} INFO - Started process (PID=21395) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:58.368+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:00:58.376+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:58.375+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:58.633+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:00:58.753+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:58.749+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:00:58.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:58.963+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:00:58.996+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:58.995+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:00:59.014+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:59.011+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:00:59.032+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:00:59.031+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:00:59.299+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.244 seconds
[2024-11-20T13:02:26.967+0700] {processor.py:186} INFO - Started process (PID=22103) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:02:27.035+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:02:27.118+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:27.099+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:02:29.114+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:02:29.882+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:29.869+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:02:31.464+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:31.455+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:02:31.610+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:31.597+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:02:31.664+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:31.651+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:02:31.760+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:02:31.748+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:02:33.206+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 6.334 seconds
[2024-11-20T13:04:50.539+0700] {processor.py:186} INFO - Started process (PID=22446) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:04:50.546+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:04:50.572+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:50.570+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:04:51.664+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:04:52.073+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:52.072+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:04:52.582+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:52.581+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:04:52.618+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:52.615+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:04:52.639+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:52.636+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:04:52.655+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:04:52.652+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:04:52.910+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.472 seconds
[2024-11-20T13:05:33.986+0700] {processor.py:186} INFO - Started process (PID=22766) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:05:33.991+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:05:34.002+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.001+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:05:34.278+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:05:34.445+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.444+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:05:34.675+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.672+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:05:34.691+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.687+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:05:34.701+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.700+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:05:34.710+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:05:34.709+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:05:34.888+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.949 seconds
[2024-11-20T13:06:08.020+0700] {processor.py:186} INFO - Started process (PID=22911) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:08.025+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:06:08.038+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.037+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:08.329+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:08.408+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.408+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:06:08.531+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.528+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:06:08.544+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.543+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:06:08.551+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.549+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:06:08.559+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:08.558+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:06:08.682+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.737 seconds
[2024-11-20T13:06:39.823+0700] {processor.py:186} INFO - Started process (PID=23069) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:39.835+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:06:39.871+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:39.864+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:40.301+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:06:40.614+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:40.612+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:06:40.771+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:40.771+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:06:40.783+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:40.783+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:06:40.789+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:40.788+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:06:40.799+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:06:40.798+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:06:40.921+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.165 seconds
[2024-11-20T13:07:11.477+0700] {processor.py:186} INFO - Started process (PID=23207) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:11.481+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:07:11.486+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.485+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:11.565+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:11.616+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.615+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:07:11.671+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.671+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:07:11.676+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.675+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:07:11.678+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.678+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:07:11.682+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:11.682+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:07:11.729+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.264 seconds
[2024-11-20T13:07:43.635+0700] {processor.py:186} INFO - Started process (PID=23364) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:43.640+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:07:43.655+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:43.654+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:44.109+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:07:44.396+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:44.391+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:07:44.700+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:44.696+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:07:44.742+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:44.737+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:07:44.757+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:44.756+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:07:44.769+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:07:44.768+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:07:44.993+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.394 seconds
[2024-11-20T13:08:17.250+0700] {processor.py:186} INFO - Started process (PID=23509) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:17.255+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:08:17.273+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.271+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:17.496+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:17.632+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.629+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:08:17.868+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.867+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:08:17.883+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.882+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:08:17.890+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.888+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:08:17.900+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:17.899+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:08:18.052+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.837 seconds
[2024-11-20T13:08:50.271+0700] {processor.py:186} INFO - Started process (PID=23644) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:50.276+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:08:50.294+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:50.292+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:50.657+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:08:50.828+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:50.827+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:08:51.003+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:51.002+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:08:51.017+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:51.017+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:08:51.026+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:51.023+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:08:51.051+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:08:51.050+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:08:51.196+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.976 seconds
[2024-11-20T13:09:21.811+0700] {processor.py:186} INFO - Started process (PID=23778) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:21.816+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:09:21.823+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:21.822+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:21.956+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:22.030+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:22.029+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:09:22.120+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:22.119+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:09:22.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:22.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:09:22.136+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:22.135+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:09:22.140+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:22.140+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:09:22.232+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.440 seconds
[2024-11-20T13:09:54.933+0700] {processor.py:186} INFO - Started process (PID=23955) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:54.936+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:09:54.948+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:54.946+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:55.357+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:09:55.600+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:55.598+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:09:55.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:55.771+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:09:55.800+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:55.799+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:09:55.808+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:55.807+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:09:55.816+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:09:55.815+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:09:55.993+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.090 seconds
[2024-11-20T13:10:26.693+0700] {processor.py:186} INFO - Started process (PID=24752) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:10:26.700+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:10:26.719+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:26.709+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:10:27.062+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:10:27.158+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.157+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:10:27.274+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.272+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:10:27.285+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.284+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:10:27.290+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.290+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:10:27.294+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.293+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:10:27.381+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.738 seconds
[2024-11-20T13:11:02.846+0700] {processor.py:186} INFO - Started process (PID=24921) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:02.852+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:11:02.868+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:02.866+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:03.373+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:03.611+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:03.610+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:11:03.932+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:03.931+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:11:03.967+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:03.966+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:11:03.977+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:03.976+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:11:04.003+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:04.002+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:11:04.668+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.853 seconds
[2024-11-20T13:11:58.082+0700] {processor.py:186} INFO - Started process (PID=25111) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:58.100+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:11:58.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:58.121+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:58.565+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:11:58.808+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:58.807+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:11:59.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:59.053+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:11:59.074+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:59.073+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:11:59.083+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:59.082+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:11:59.090+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:11:59.089+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:12:01.866+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 3.873 seconds
[2024-11-20T13:12:37.766+0700] {processor.py:186} INFO - Started process (PID=25329) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:12:37.771+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:12:37.779+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:37.777+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:12:37.932+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:12:38.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:38.034+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:12:38.150+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:38.148+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:12:38.163+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:38.162+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:12:38.174+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:38.172+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:12:38.189+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:12:38.187+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:12:38.457+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.722 seconds
[2024-11-20T13:13:08.764+0700] {processor.py:186} INFO - Started process (PID=25491) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:08.771+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:13:08.786+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:08.782+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:09.070+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:09.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:09.203+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:13:09.341+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:09.341+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:13:09.351+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:09.350+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:13:09.356+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:09.356+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:13:09.363+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:09.362+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:13:09.470+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.738 seconds
[2024-11-20T13:13:39.961+0700] {processor.py:186} INFO - Started process (PID=25658) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:39.965+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:13:39.970+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:39.969+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:40.056+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:13:40.105+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:40.105+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:13:40.177+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:40.176+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:13:40.182+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:40.182+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:13:40.185+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:40.185+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:13:40.189+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:13:40.188+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:13:40.237+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.287 seconds
[2024-11-20T13:14:10.392+0700] {processor.py:186} INFO - Started process (PID=25796) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:10.394+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:14:10.397+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.396+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:10.462+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:10.496+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.496+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:14:10.534+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.533+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:14:10.537+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.537+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:14:10.539+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.539+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:14:10.541+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:10.541+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:14:10.578+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.194 seconds
[2024-11-20T13:14:40.706+0700] {processor.py:186} INFO - Started process (PID=25931) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:40.710+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:14:40.713+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.713+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:40.777+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:14:40.810+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.810+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:14:40.845+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.844+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:14:40.849+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.848+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:14:40.851+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.850+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:14:40.853+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:14:40.852+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:14:40.887+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.190 seconds
[2024-11-20T13:15:11.471+0700] {processor.py:186} INFO - Started process (PID=26069) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:11.475+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:15:11.481+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.480+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:11.559+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:11.596+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.596+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:15:11.637+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.637+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:15:11.643+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.643+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:15:11.646+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.645+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:15:11.650+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:11.650+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:15:11.689+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.227 seconds
[2024-11-20T13:15:42.009+0700] {processor.py:186} INFO - Started process (PID=26207) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:42.011+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:15:42.015+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.015+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:42.083+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:15:42.117+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.117+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:15:42.159+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.158+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:15:42.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.162+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:15:42.165+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.164+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:15:42.167+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:15:42.166+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:15:42.207+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.214 seconds
[2024-11-20T13:16:12.302+0700] {processor.py:186} INFO - Started process (PID=26337) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:12.307+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:16:12.321+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:12.318+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:12.810+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:12.962+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:12.961+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:16:13.117+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.116+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:16:13.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.129+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:16:13.137+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.136+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:16:13.144+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.143+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:16:13.274+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.009 seconds
[2024-11-20T13:16:43.765+0700] {processor.py:186} INFO - Started process (PID=26502) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:43.768+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:16:43.771+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.771+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:43.839+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:16:43.878+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.878+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:16:43.915+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.915+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:16:43.919+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.919+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:16:43.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.921+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:16:43.923+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.923+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:16:43.960+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.204 seconds
[2024-11-20T13:17:14.309+0700] {processor.py:186} INFO - Started process (PID=26635) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:14.312+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:17:14.317+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.317+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:14.403+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:14.439+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.438+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:17:14.485+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.484+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:17:14.490+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.489+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:17:14.492+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.491+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:17:14.494+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:14.493+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:17:14.534+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.235 seconds
[2024-11-20T13:17:45.304+0700] {processor.py:186} INFO - Started process (PID=26838) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:45.308+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:17:45.314+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.313+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:45.402+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:17:45.445+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.445+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:17:45.496+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.495+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:17:45.502+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.501+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:17:45.504+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.504+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:17:45.506+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:17:45.506+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:17:45.551+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.262 seconds
[2024-11-20T13:18:16.226+0700] {processor.py:186} INFO - Started process (PID=26968) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:16.229+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:18:16.233+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.233+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:16.320+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:16.375+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.375+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:18:16.435+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.432+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:18:16.443+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.443+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:18:16.447+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.446+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:18:16.449+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:16.449+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:18:16.498+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.285 seconds
[2024-11-20T13:18:46.710+0700] {processor.py:186} INFO - Started process (PID=27097) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:46.712+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:18:46.719+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.718+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:46.802+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:18:46.846+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.846+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:18:46.892+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.891+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:18:46.896+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.896+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:18:46.898+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.898+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:18:46.901+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:18:46.901+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:18:46.943+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.244 seconds
[2024-11-20T13:19:17.286+0700] {processor.py:186} INFO - Started process (PID=27235) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:17.291+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:19:17.304+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.303+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:17.690+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:17.808+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.807+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:19:17.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:19:17.961+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.960+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:19:17.968+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.967+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:19:17.977+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:17.977+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:19:18.096+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.846 seconds
[2024-11-20T13:19:48.496+0700] {processor.py:186} INFO - Started process (PID=27366) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:48.500+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:19:48.510+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.509+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:48.674+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:19:48.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.749+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:19:48.836+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.836+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:19:48.846+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.845+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:19:48.850+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.850+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:19:48.856+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:19:48.855+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:19:48.932+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.459 seconds
[2024-11-20T13:20:19.801+0700] {processor.py:186} INFO - Started process (PID=27502) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:19.805+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:20:19.812+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:19.811+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:19.959+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:20.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:20.035+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:20:20.115+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:20.115+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:20:20.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:20.123+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:20:20.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:20.131+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:20:20.135+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:20.135+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:20:20.205+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.425 seconds
[2024-11-20T13:20:50.709+0700] {processor.py:186} INFO - Started process (PID=27630) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:50.714+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:20:50.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:50.720+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:50.867+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:20:50.951+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:50.951+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:20:51.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:51.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:20:51.061+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:51.060+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:20:51.067+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:51.066+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:20:51.071+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:20:51.071+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:20:51.160+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.470 seconds
[2024-11-20T13:21:21.553+0700] {processor.py:186} INFO - Started process (PID=27763) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:21.555+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:21:21.558+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.557+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:21.627+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:21.663+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.663+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:21:21.711+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.711+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:21:21.715+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.715+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:21:21.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.718+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:21:21.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:21.720+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:21:21.766+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.223 seconds
[2024-11-20T13:21:51.983+0700] {processor.py:186} INFO - Started process (PID=27892) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:51.984+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:21:51.988+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:51.988+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:52.079+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:21:52.133+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:52.132+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:21:52.198+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:52.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:21:52.205+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:52.204+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:21:52.208+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:52.207+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:21:52.212+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:21:52.211+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:21:52.287+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.317 seconds
[2024-11-20T13:22:22.424+0700] {processor.py:186} INFO - Started process (PID=28028) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:22.425+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:22:22.428+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.428+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:22.508+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:22.542+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.542+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:22:22.580+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.580+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:22:22.585+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.584+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:22:22.587+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.587+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:22:22.589+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:22.589+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:22:22.629+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.215 seconds
[2024-11-20T13:22:52.790+0700] {processor.py:186} INFO - Started process (PID=28187) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:52.792+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:22:52.796+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.795+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:52.868+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:22:52.902+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.901+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:22:52.940+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.940+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:22:52.944+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.944+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:22:52.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:22:52.949+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:22:52.949+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:22:52.990+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.209 seconds
[2024-11-20T13:23:23.292+0700] {processor.py:186} INFO - Started process (PID=28335) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:23.293+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:23:23.296+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.296+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:23.372+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:23.408+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.408+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:23:23.448+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.448+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:23:23.453+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.452+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:23:23.455+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.454+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:23:23.456+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:23.456+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:23:23.490+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.207 seconds
[2024-11-20T13:23:55.408+0700] {processor.py:186} INFO - Started process (PID=28493) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:55.411+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:23:55.417+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.416+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:55.543+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:23:55.600+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.599+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:23:55.664+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.663+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:23:55.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.669+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:23:55.673+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.673+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:23:55.677+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:23:55.676+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:23:55.740+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.347 seconds
[2024-11-20T13:24:27.520+0700] {processor.py:186} INFO - Started process (PID=28644) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:27.522+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:24:27.528+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:27.527+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:27.651+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:27.710+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:27.710+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:24:28.118+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:28.117+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:24:28.126+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:28.125+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:24:28.130+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:28.130+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:24:28.138+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:28.137+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:24:28.210+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.708 seconds
[2024-11-20T13:24:58.509+0700] {processor.py:186} INFO - Started process (PID=28793) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:58.512+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:24:58.521+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:58.520+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:58.752+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:24:58.892+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:58.891+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:24:59.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:59.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:24:59.058+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:59.057+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:24:59.066+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:59.066+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:24:59.078+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:24:59.077+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:24:59.758+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.272 seconds
[2024-11-20T13:25:30.521+0700] {processor.py:186} INFO - Started process (PID=28941) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:25:30.522+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:25:30.524+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.524+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:25:30.571+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:25:30.596+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.596+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:25:30.631+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.630+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:25:30.633+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.633+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:25:30.635+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.635+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:25:30.638+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:25:30.638+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:25:30.876+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.365 seconds
[2024-11-20T13:26:01.308+0700] {processor.py:186} INFO - Started process (PID=29067) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:01.311+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:26:01.318+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.316+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:01.466+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:01.572+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.570+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:26:01.676+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.675+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:26:01.689+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.689+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:26:01.696+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.695+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:26:01.701+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:01.700+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:26:01.784+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.500 seconds
[2024-11-20T13:26:31.883+0700] {processor.py:186} INFO - Started process (PID=29200) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:31.884+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:26:31.888+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:31.888+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:31.968+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:26:32.009+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:32.008+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:26:32.056+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:32.056+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:26:32.061+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:32.061+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:26:32.063+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:32.063+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:26:32.066+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:26:32.066+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:26:32.111+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.238 seconds
[2024-11-20T13:27:02.179+0700] {processor.py:186} INFO - Started process (PID=29347) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:02.182+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:27:02.188+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.187+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:02.341+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:02.407+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.406+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:27:02.483+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.482+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:27:02.492+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.491+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:27:02.496+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.495+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:27:02.499+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:02.498+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:27:02.574+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.413 seconds
[2024-11-20T13:27:48.546+0700] {processor.py:186} INFO - Started process (PID=29854) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:48.551+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:27:48.561+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:48.559+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:48.830+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:27:48.993+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:48.991+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:27:49.207+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.206+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:27:49.225+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.224+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:27:49.235+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.233+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:27:49.245+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.245+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:27:49.425+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.919 seconds
[2024-11-20T13:28:19.868+0700] {processor.py:186} INFO - Started process (PID=30002) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:19.870+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:28:19.874+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:19.873+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:19.967+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:20.015+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.015+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:28:20.067+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.067+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:28:20.073+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:28:20.087+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.087+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:28:20.090+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.090+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:28:20.139+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.283 seconds
[2024-11-20T13:28:51.402+0700] {processor.py:186} INFO - Started process (PID=30349) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:51.408+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:28:51.418+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:51.417+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:51.786+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:28:52.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:52.158+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:28:52.472+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:52.471+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:28:52.499+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:52.494+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:28:52.509+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:52.508+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:28:52.527+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:28:52.526+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:28:52.971+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.596 seconds
[2024-11-20T13:29:27.881+0700] {processor.py:186} INFO - Started process (PID=30549) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:27.895+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:29:27.906+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:27.905+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:28.253+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:28.379+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:28.379+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:29:28.517+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:28.516+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:29:28.537+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:28.531+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:29:28.551+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:28.545+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:29:28.568+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:28.567+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:29:29.003+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.220 seconds
[2024-11-20T13:29:59.570+0700] {processor.py:186} INFO - Started process (PID=30696) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:59.571+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:29:59.574+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.573+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:59.677+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:29:59.744+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.744+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:29:59.825+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.824+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:29:59.833+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.832+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:29:59.838+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.837+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:29:59.842+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:29:59.841+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:29:59.902+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.346 seconds
[2024-11-20T13:30:32.633+0700] {processor.py:186} INFO - Started process (PID=30877) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:30:32.641+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:30:32.651+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:32.649+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:30:32.882+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:30:32.997+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:32.996+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:30:33.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:33.123+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:30:33.141+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:33.140+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:30:33.155+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:33.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:30:33.168+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:30:33.167+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:30:33.314+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.728 seconds
[2024-11-20T13:31:05.864+0700] {processor.py:186} INFO - Started process (PID=31040) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:05.869+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:31:05.878+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:05.877+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:06.114+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:06.254+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:06.253+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:31:06.406+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:06.405+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:31:06.426+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:06.425+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:31:06.437+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:06.436+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:31:06.447+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:06.446+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:31:06.582+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.755 seconds
[2024-11-20T13:31:36.904+0700] {processor.py:186} INFO - Started process (PID=31242) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:36.909+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:31:36.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:36.917+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:37.345+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:31:37.701+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:37.700+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:31:38.098+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:38.096+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:31:38.192+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:38.191+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:31:38.263+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:38.256+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:31:38.294+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:31:38.293+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:31:38.579+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.749 seconds
[2024-11-20T13:32:17.488+0700] {processor.py:186} INFO - Started process (PID=31500) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:32:17.517+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:32:17.545+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:17.543+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:32:17.928+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:32:18.081+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:18.080+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:32:18.497+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:18.491+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:32:18.532+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:18.532+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:32:18.556+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:18.546+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:32:18.589+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:32:18.585+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:32:19.074+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.662 seconds
[2024-11-20T13:33:03.530+0700] {processor.py:186} INFO - Started process (PID=32142) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:03.545+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:33:03.572+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:03.570+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:04.322+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:05.152+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.148+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:33:05.371+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.364+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:33:05.384+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.382+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:33:05.393+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.392+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:33:05.405+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:33:05.521+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.138 seconds
[2024-11-20T13:33:36.574+0700] {processor.py:186} INFO - Started process (PID=32399) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:36.577+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:33:36.584+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.583+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:36.717+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:33:36.831+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.830+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:33:36.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.920+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:33:36.966+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.965+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:33:36.974+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.973+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:33:36.981+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.980+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:33:37.046+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.493 seconds
[2024-11-20T13:34:09.061+0700] {processor.py:186} INFO - Started process (PID=32589) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:34:09.066+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:34:09.082+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.079+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:34:09.298+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:34:09.394+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.394+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:34:09.499+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.498+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:34:09.506+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.506+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:34:09.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.510+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:34:09.516+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.515+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:34:09.595+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.563 seconds
[2024-11-20T13:35:19.908+0700] {processor.py:186} INFO - Started process (PID=32983) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:35:19.958+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:35:20.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:20.018+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:35:20.511+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:35:21.015+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:21.013+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:35:21.761+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:21.759+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:35:21.808+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:21.807+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:35:21.825+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:21.818+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:35:21.839+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:35:21.838+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:35:23.290+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 3.632 seconds
[2024-11-20T13:36:18.270+0700] {processor.py:186} INFO - Started process (PID=33424) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:36:18.277+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:36:18.292+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:18.289+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:36:18.595+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:36:18.832+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:18.831+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:36:19.159+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:19.158+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:36:19.174+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:19.173+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:36:19.178+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:19.177+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:36:19.181+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:36:19.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:36:19.367+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.144 seconds
[2024-11-20T13:37:07.682+0700] {processor.py:186} INFO - Started process (PID=33930) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:07.695+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:37:07.729+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:07.726+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:08.201+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:08.396+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:08.394+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:37:09.118+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:09.114+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:37:09.171+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:09.170+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:37:09.199+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:09.193+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:37:09.256+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:09.254+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:37:10.571+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.978 seconds
[2024-11-20T13:37:40.999+0700] {processor.py:186} INFO - Started process (PID=34165) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:41.023+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:37:41.028+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.028+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:41.116+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:37:41.184+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.183+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:37:41.268+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.267+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:37:41.277+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.276+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:37:41.281+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.281+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:37:41.286+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:37:41.286+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:37:41.375+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.380 seconds
[2024-11-20T13:38:47.662+0700] {processor.py:186} INFO - Started process (PID=34474) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:38:47.670+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:38:47.695+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:47.693+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:38:48.374+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:38:48.638+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:48.635+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:38:49.006+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:48.997+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:38:49.093+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:49.083+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:38:49.131+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:49.124+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:38:49.188+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:38:49.186+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:38:49.952+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 2.426 seconds
[2024-11-20T13:39:20.743+0700] {processor.py:186} INFO - Started process (PID=34692) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:20.747+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:39:20.751+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.751+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:20.844+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:20.888+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.888+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:39:20.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.947+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:39:20.954+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.953+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:39:20.957+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.956+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:39:20.959+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:20.959+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:39:21.015+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.282 seconds
[2024-11-20T13:39:51.495+0700] {processor.py:186} INFO - Started process (PID=34905) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:51.502+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:39:51.510+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:51.508+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:51.991+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:39:52.177+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:52.176+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:39:52.326+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:52.325+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:39:52.350+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:52.348+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:39:52.360+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:52.358+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:39:52.367+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:39:52.366+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:39:52.500+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.046 seconds
[2024-11-20T13:40:23.230+0700] {processor.py:186} INFO - Started process (PID=35136) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:23.231+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:40:23.238+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.236+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:23.299+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:23.333+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.331+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:40:23.368+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.368+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:40:23.371+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.371+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:40:23.373+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.373+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:40:23.375+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:23.375+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:40:23.398+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.175 seconds
[2024-11-20T13:40:53.982+0700] {processor.py:186} INFO - Started process (PID=35383) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:53.984+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:40:53.989+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:53.987+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:54.160+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:40:54.409+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:54.408+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:40:54.620+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:54.618+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:40:54.633+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:54.632+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:40:54.647+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:54.644+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:40:54.661+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:40:54.658+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:40:54.799+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.838 seconds
[2024-11-20T13:41:25.480+0700] {processor.py:186} INFO - Started process (PID=35590) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:25.481+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:41:25.483+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.482+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:25.543+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:25.574+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.573+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:41:25.615+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.614+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:41:25.619+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.619+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:41:25.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.621+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:41:25.624+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:25.623+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:41:25.666+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.194 seconds
[2024-11-20T13:41:55.885+0700] {processor.py:186} INFO - Started process (PID=35735) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:55.886+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:41:55.888+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:55.887+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:55.961+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:41:56.004+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:56.004+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:41:56.047+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:56.047+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:41:56.051+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:56.051+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:41:56.054+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:56.053+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:41:56.056+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:41:56.056+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:41:56.101+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.227 seconds
[2024-11-20T13:42:26.834+0700] {processor.py:186} INFO - Started process (PID=35884) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:26.838+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:42:26.841+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:26.840+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:26.941+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:26.997+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:26.997+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:42:27.064+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:27.064+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:42:27.070+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:27.069+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:42:27.073+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:27.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:42:27.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:27.075+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:42:27.128+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.307 seconds
[2024-11-20T13:42:57.411+0700] {processor.py:186} INFO - Started process (PID=36154) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:57.412+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:42:57.413+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.413+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:57.457+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:42:57.485+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.485+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:42:57.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.511+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:42:57.513+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.513+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:42:57.515+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.515+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:42:57.517+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:42:57.517+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:42:57.543+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.139 seconds
[2024-11-20T13:43:28.330+0700] {processor.py:186} INFO - Started process (PID=36469) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:43:28.332+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:43:28.335+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.335+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:43:28.451+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:43:28.514+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.513+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:43:28.599+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.598+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:43:28.609+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.608+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:43:28.612+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.612+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:43:28.615+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:43:28.615+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:43:28.697+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.381 seconds
[2024-11-20T13:44:02.788+0700] {processor.py:186} INFO - Started process (PID=36733) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:02.807+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:44:02.811+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:02.810+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:03.028+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:03.159+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:03.157+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:44:03.309+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:03.307+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:44:03.332+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:03.331+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:44:03.344+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:03.343+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:44:03.350+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:03.349+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:44:03.472+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.704 seconds
[2024-11-20T13:44:33.697+0700] {processor.py:186} INFO - Started process (PID=36955) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:33.703+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:44:33.717+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:33.714+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:34.095+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:44:34.207+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:34.206+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:44:34.386+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:34.385+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:44:34.403+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:34.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:44:34.407+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:34.407+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:44:34.419+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:44:34.418+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:44:34.534+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.906 seconds
[2024-11-20T13:45:05.198+0700] {processor.py:186} INFO - Started process (PID=37198) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:05.200+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:45:05.202+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.202+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:05.295+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:05.337+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.337+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:45:05.380+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.380+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:45:05.384+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.384+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:45:05.386+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.386+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:45:05.388+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:05.388+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:45:05.440+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.252 seconds
[2024-11-20T13:45:37.386+0700] {processor.py:186} INFO - Started process (PID=37625) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:37.396+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:45:37.410+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:37.408+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:37.923+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:45:38.219+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:38.217+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:45:38.613+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:38.608+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:45:38.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:38.668+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:45:38.698+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:38.688+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:45:38.712+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:45:38.708+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:45:38.953+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.608 seconds
[2024-11-20T13:46:16.227+0700] {processor.py:186} INFO - Started process (PID=38068) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:16.239+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:46:16.243+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:16.242+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:16.679+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:16.890+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:16.889+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:46:17.178+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:17.177+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:46:17.189+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:17.188+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:46:17.194+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:17.193+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:46:17.198+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:17.197+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:46:17.368+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.238 seconds
[2024-11-20T13:46:54.827+0700] {processor.py:186} INFO - Started process (PID=38494) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:54.833+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:46:54.847+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:54.842+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:55.640+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:46:56.403+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:56.394+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:46:57.584+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:57.578+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:46:57.659+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:57.658+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:46:57.728+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:57.725+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:46:57.788+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:46:57.786+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:46:58.341+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 3.599 seconds
[2024-11-20T13:47:37.618+0700] {processor.py:186} INFO - Started process (PID=39034) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:47:37.623+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:47:37.627+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.626+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:47:37.780+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:47:37.857+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.856+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:47:37.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.916+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:47:37.926+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:47:37.930+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.929+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:47:37.932+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:47:37.932+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:47:38.002+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.403 seconds
[2024-11-20T13:48:32.353+0700] {processor.py:186} INFO - Started process (PID=39519) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:48:32.376+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:48:32.405+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:32.382+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:48:33.112+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:48:34.486+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:34.479+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:48:35.548+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:35.547+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:48:35.621+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:35.616+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:48:35.684+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:35.664+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:48:35.736+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:48:35.728+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:48:36.381+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 4.095 seconds
[2024-11-20T13:49:12.191+0700] {processor.py:186} INFO - Started process (PID=39856) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:49:12.195+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:49:12.202+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.199+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:49:12.444+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:49:12.550+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.549+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:49:12.673+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.672+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:49:12.681+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.681+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:49:12.685+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.684+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:49:12.687+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:49:12.687+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:49:12.769+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.599 seconds
[2024-11-20T13:50:15.342+0700] {processor.py:186} INFO - Started process (PID=40338) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:50:15.373+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:50:15.406+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:15.400+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:50:17.002+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:50:18.072+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:18.070+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:50:19.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:19.078+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:50:19.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:19.150+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:50:19.204+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:19.190+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:50:19.228+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:50:19.227+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:50:20.426+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 5.414 seconds
[2024-11-20T13:52:40.895+0700] {processor.py:186} INFO - Started process (PID=41289) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:52:40.906+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:52:40.917+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:40.916+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:52:41.269+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:52:41.582+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:41.576+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:52:41.864+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:41.863+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:52:41.897+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:41.888+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:52:41.919+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:41.918+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:52:41.931+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:52:41.930+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:52:42.242+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.461 seconds
[2024-11-20T13:53:13.195+0700] {processor.py:186} INFO - Started process (PID=41567) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:13.200+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:53:13.211+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:13.210+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:13.573+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:13.886+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:13.885+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:53:14.430+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:14.429+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:53:14.490+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:14.482+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:53:14.508+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:14.508+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:53:14.531+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:14.531+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:53:14.912+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.786 seconds
[2024-11-20T13:53:46.339+0700] {processor.py:186} INFO - Started process (PID=41863) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:46.349+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:53:46.365+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:46.359+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:46.641+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:53:46.925+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:46.925+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:53:47.133+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:47.132+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:53:47.142+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:47.142+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:53:47.162+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:47.161+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:53:47.165+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:53:47.165+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:53:47.244+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.970 seconds
[2024-11-20T13:54:17.486+0700] {processor.py:186} INFO - Started process (PID=42151) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:17.492+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:54:17.501+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:17.496+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:17.797+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:17.869+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:17.868+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:54:18.026+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:18.025+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:54:18.035+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:18.034+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:54:18.044+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:18.044+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:54:18.049+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:18.049+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:54:18.229+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.774 seconds
[2024-11-20T13:54:50.221+0700] {processor.py:186} INFO - Started process (PID=42447) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:50.238+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:54:50.287+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:50.274+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:50.854+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:54:51.040+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:51.038+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:54:51.271+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:51.270+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:54:51.307+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:51.306+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:54:51.323+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:51.323+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:54:51.343+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:54:51.342+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:54:51.529+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.379 seconds
[2024-11-20T13:55:21.865+0700] {processor.py:186} INFO - Started process (PID=42722) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:21.866+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:55:21.867+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:21.867+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:21.966+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:22.004+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:22.003+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:55:22.040+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:22.039+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:55:22.044+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:22.043+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:55:22.046+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:22.045+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:55:22.047+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:22.047+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:55:22.349+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.493 seconds
[2024-11-20T13:55:53.066+0700] {processor.py:186} INFO - Started process (PID=42995) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:53.069+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:55:53.084+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.078+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:53.230+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:55:53.374+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.373+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:55:53.544+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.544+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:55:53.550+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.550+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:55:53.556+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.555+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:55:53.558+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:55:53.558+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:55:53.732+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.716 seconds
[2024-11-20T13:56:28.711+0700] {processor.py:186} INFO - Started process (PID=43287) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:56:28.723+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:56:28.728+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:28.725+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:56:29.128+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:56:29.307+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:29.306+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:56:29.498+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:29.497+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:56:29.506+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:29.506+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:56:29.511+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:29.510+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:56:29.515+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:56:29.514+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:56:29.618+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.935 seconds
[2024-11-20T13:57:00.522+0700] {processor.py:186} INFO - Started process (PID=43627) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:00.523+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:57:00.526+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.525+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:00.668+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:00.853+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.852+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:57:00.955+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.955+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:57:00.964+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.963+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:57:00.970+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.969+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:57:00.975+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:00.975+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:57:01.031+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.530 seconds
[2024-11-20T13:57:31.465+0700] {processor.py:186} INFO - Started process (PID=44179) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:31.474+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:57:31.476+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.476+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:31.559+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:57:31.607+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.606+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:57:31.662+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.661+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:57:31.670+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.670+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:57:31.678+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.675+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:57:31.683+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:57:31.682+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:57:31.765+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.317 seconds
[2024-11-20T13:58:02.292+0700] {processor.py:186} INFO - Started process (PID=44470) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:02.303+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:58:02.313+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:02.312+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:02.638+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:02.812+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:02.811+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:58:03.072+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:03.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:58:03.107+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:03.106+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:58:03.139+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:03.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:58:03.166+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:03.149+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:58:03.627+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.411 seconds
[2024-11-20T13:58:33.974+0700] {processor.py:186} INFO - Started process (PID=44734) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:33.976+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:58:33.978+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:33.977+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:34.037+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:58:34.084+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:34.084+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:58:34.116+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:34.116+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:58:34.120+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:34.119+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:58:34.124+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:34.124+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:58:34.126+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:58:34.125+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:58:34.165+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.198 seconds
[2024-11-20T13:59:04.475+0700] {processor.py:186} INFO - Started process (PID=45015) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:04.479+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:59:04.481+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.480+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:04.631+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:04.684+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.684+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:59:04.744+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.743+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:59:04.749+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.748+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:59:04.753+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.753+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:59:04.756+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:04.755+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:59:04.817+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.362 seconds
[2024-11-20T13:59:35.688+0700] {processor.py:186} INFO - Started process (PID=45290) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:35.694+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T13:59:35.700+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:35.699+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:35.960+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T13:59:36.047+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:36.046+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T13:59:36.149+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:36.148+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T13:59:36.166+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:36.165+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T13:59:36.181+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:36.180+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T13:59:36.193+0700] {logging_mixin.py:190} INFO - [2024-11-20T13:59:36.190+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T13:59:36.305+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.651 seconds
[2024-11-20T14:00:06.981+0700] {processor.py:186} INFO - Started process (PID=45553) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:06.982+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:00:06.984+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:06.983+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:07.154+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:07.248+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:07.247+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:00:07.358+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:07.357+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:00:07.366+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:07.366+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:00:07.371+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:07.371+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:00:07.391+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:07.380+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:00:07.465+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.501 seconds
[2024-11-20T14:00:37.783+0700] {processor.py:186} INFO - Started process (PID=45816) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:37.791+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:00:37.795+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:37.793+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:37.933+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:00:37.985+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:37.985+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:00:38.056+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:38.056+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:00:38.064+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:38.064+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:00:38.076+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:38.075+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:00:38.079+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:00:38.079+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:00:38.155+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.390 seconds
[2024-11-20T14:01:09.036+0700] {processor.py:186} INFO - Started process (PID=46072) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:09.039+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:01:09.042+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.041+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:09.343+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:09.549+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.548+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:01:09.745+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.740+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:01:09.775+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.774+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:01:09.798+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.797+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:01:09.821+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:09.820+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:01:10.094+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.074 seconds
[2024-11-20T14:01:40.960+0700] {processor.py:186} INFO - Started process (PID=46365) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:40.961+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:01:40.963+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:40.962+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:41.019+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:01:41.050+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:41.050+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:01:41.089+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:41.089+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:01:41.092+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:41.092+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:01:41.094+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:41.094+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:01:41.096+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:01:41.095+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:01:41.126+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.173 seconds
[2024-11-20T14:02:11.245+0700] {processor.py:186} INFO - Started process (PID=46624) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:11.246+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:02:11.248+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.248+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:11.330+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:11.364+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.364+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:02:11.398+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.398+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:02:11.401+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.401+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:02:11.403+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:02:11.405+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:11.404+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:02:11.438+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.200 seconds
[2024-11-20T14:02:42.052+0700] {processor.py:186} INFO - Started process (PID=46922) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:42.084+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:02:42.096+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.088+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:42.600+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:02:42.732+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.731+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:02:42.947+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:02:42.956+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.955+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:02:42.960+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.959+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:02:42.967+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:02:42.966+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:02:43.095+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.076 seconds
[2024-11-20T14:03:20.512+0700] {processor.py:186} INFO - Started process (PID=47240) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:20.515+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:03:20.529+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.517+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:20.665+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:20.727+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.726+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:03:20.791+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.790+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:03:20.796+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.795+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:03:20.798+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.798+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:03:20.800+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:20.800+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:03:20.854+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.368 seconds
[2024-11-20T14:03:51.491+0700] {processor.py:186} INFO - Started process (PID=47497) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:51.502+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:03:51.507+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.503+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:51.620+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:03:51.690+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.689+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:03:51.765+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.764+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:03:51.770+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.769+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:03:51.774+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.773+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:03:51.779+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:03:51.779+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:03:51.858+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.393 seconds
[2024-11-20T14:04:22.180+0700] {processor.py:186} INFO - Started process (PID=47785) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:04:22.182+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:04:22.185+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.184+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:04:22.340+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:04:22.410+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.410+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:04:22.476+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.476+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:04:22.483+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.482+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:04:22.486+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.486+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:04:22.490+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:04:22.489+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:04:22.576+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.419 seconds
[2024-11-20T14:05:03.120+0700] {processor.py:186} INFO - Started process (PID=48120) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:03.129+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:05:03.132+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.131+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:03.396+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:03.530+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.529+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:05:03.695+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.692+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:05:03.712+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.711+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:05:03.718+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.717+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:05:03.721+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:03.721+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:05:03.903+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.827 seconds
[2024-11-20T14:05:34.716+0700] {processor.py:186} INFO - Started process (PID=48415) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:34.717+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:05:34.719+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.718+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:34.829+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:05:34.875+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.874+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:05:34.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.921+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:05:34.925+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.925+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:05:34.928+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.928+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:05:34.931+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:05:34.930+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:05:34.978+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.272 seconds
[2024-11-20T14:06:05.106+0700] {processor.py:186} INFO - Started process (PID=48671) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:05.110+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:06:05.113+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.112+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:05.276+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:05.432+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.431+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:06:05.545+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.545+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:06:05.557+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.555+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:06:05.561+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.560+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:06:05.569+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:05.567+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:06:05.715+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.642 seconds
[2024-11-20T14:06:36.927+0700] {processor.py:186} INFO - Started process (PID=48955) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:36.932+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:06:36.936+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:36.935+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:37.073+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:06:37.132+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:37.131+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:06:37.212+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:37.210+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:06:37.223+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:37.222+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:06:37.229+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:37.228+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:06:37.238+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:06:37.237+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:06:37.323+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.421 seconds
[2024-11-20T14:07:07.851+0700] {processor.py:186} INFO - Started process (PID=49294) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:07.853+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:07:07.855+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:07.854+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:07.958+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:08.004+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:08.004+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:07:08.070+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:08.070+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:07:08.075+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:08.074+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:07:08.077+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:08.077+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:07:08.086+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:08.085+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:07:08.154+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.323 seconds
[2024-11-20T14:07:38.459+0700] {processor.py:186} INFO - Started process (PID=49657) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:38.464+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:07:38.468+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.466+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:38.616+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:07:38.667+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.666+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:07:38.766+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.765+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:07:38.772+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.771+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:07:38.777+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.775+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:07:38.779+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:07:38.779+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:07:38.850+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.442 seconds
[2024-11-20T14:08:09.019+0700] {processor.py:186} INFO - Started process (PID=49943) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:09.023+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:08:09.026+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.025+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:09.228+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:09.336+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.335+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:08:09.433+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.432+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:08:09.442+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.442+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:08:09.448+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.446+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:08:09.456+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:09.454+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:08:09.538+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.544 seconds
[2024-11-20T14:08:39.884+0700] {processor.py:186} INFO - Started process (PID=50225) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:39.893+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:08:39.896+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:39.895+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:40.386+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:08:40.487+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:40.486+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:08:40.699+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:40.699+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:08:40.716+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:40.715+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:08:40.725+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:40.724+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:08:40.733+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:08:40.732+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:08:40.914+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 1.065 seconds
[2024-11-20T14:09:11.830+0700] {processor.py:186} INFO - Started process (PID=50489) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:09:11.834+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:09:11.838+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:11.836+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:09:11.976+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:09:12.049+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:12.049+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:09:12.134+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:12.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:09:12.144+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:12.143+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:09:12.148+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:12.147+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:09:12.152+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:09:12.151+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:09:12.239+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.449 seconds
[2024-11-20T14:10:20.359+0700] {processor.py:186} INFO - Started process (PID=50931) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:20.646+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:10:20.649+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:20.648+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:20.820+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:20.921+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:20.920+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:10:21.031+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:21.031+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:10:21.043+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:21.041+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:10:21.050+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:21.047+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:10:21.055+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:21.054+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:10:21.156+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.826 seconds
[2024-11-20T14:10:51.293+0700] {processor.py:186} INFO - Started process (PID=51278) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:51.295+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:10:51.297+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.297+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:51.419+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:10:51.474+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.474+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:10:51.534+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.533+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:10:51.540+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.539+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:10:51.543+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.543+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:10:51.546+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:10:51.546+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:10:51.609+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.331 seconds
[2024-11-20T14:11:22.188+0700] {processor.py:186} INFO - Started process (PID=51534) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:22.191+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:11:22.199+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.198+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:22.684+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:22.860+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.859+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:11:22.970+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.969+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:11:22.979+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.979+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:11:22.983+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.983+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:11:22.987+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:22.986+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:11:23.111+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.961 seconds
[2024-11-20T14:11:54.024+0700] {processor.py:186} INFO - Started process (PID=51794) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:54.029+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:11:54.034+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.032+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:54.187+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:11:54.278+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.277+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:11:54.389+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.389+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:11:54.397+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.396+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:11:54.400+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.400+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:11:54.404+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:11:54.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:11:54.497+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.490 seconds
[2024-11-20T14:12:25.070+0700] {processor.py:186} INFO - Started process (PID=52065) to work on /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:12:25.075+0700] {processor.py:914} INFO - Processing file /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-11-20T14:12:25.091+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.089+0700] {dagbag.py:588} INFO - Filling up the DagBag from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:12:25.326+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-11-20T14:12:25.433+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.432+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-11-20T14:12:25.591+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.590+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-11-20T14:12:25.608+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.607+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-11-20T14:12:25.613+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.612+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-11-20T14:12:25.619+0700] {logging_mixin.py:190} INFO - [2024-11-20T14:12:25.618+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-11-20T14:12:25.751+0700] {processor.py:208} INFO - Processing /home/fabian4819/REKAYASA DATA/final-exam-etl-pipeline-project/airflow-env/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.770 seconds
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          